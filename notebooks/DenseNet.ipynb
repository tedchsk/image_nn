{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9285ba0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GPUs\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch import Tensor\n",
    "import torch.utils.checkpoint as cp\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from collections import OrderedDict\n",
    "import numpy as np\n",
    "import ast\n",
    "import time\n",
    "from typing import Type, Any, Callable, Union, List, Optional\n",
    "from torch import Tensor \n",
    "from torchsummary import summary\n",
    "if torch.cuda.is_available():\n",
    "    print(\"Using GPUs\")\n",
    "    device = torch.device(\"cuda\") \n",
    "else:\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e20cc1bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "{'train': 50000, 'test': 5000, 'validation': 5000}\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(43)\n",
    "batch_size = 32\n",
    "\n",
    "### for CIFAR 10\n",
    "# stats = ((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n",
    "## for CIFAR 100\n",
    "stats = ((0.507, 0.487, 0.441), (0.267, 0.256, 0.276))\n",
    "\n",
    "transform = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.ToTensor(),\n",
    "    torchvision.transforms.Normalize(*stats),\n",
    "    torchvision.transforms.RandomCrop(32, padding=4, padding_mode='constant'),\n",
    "    torchvision.transforms.RandomHorizontalFlip(p=0.5)\n",
    "])\n",
    "\n",
    "train_set = torchvision.datasets.CIFAR100(root=\"data\", train=True, download=True, transform=transform)\n",
    "train_size = len(train_set)\n",
    "test_set = torchvision.datasets.CIFAR100(root=\"data\", train=False, download=True, transform=transform)\n",
    "test_set, validation_set = torch.utils.data.random_split(test_set, [5000, 5000])\n",
    "test_size = len(test_set)\n",
    "validation_size = len(validation_set)\n",
    "\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_set, batch_size, shuffle=True, num_workers=4, pin_memory=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_set, batch_size, num_workers=4, pin_memory=True)\n",
    "validation_loader = torch.utils.data.DataLoader(validation_set, batch_size, num_workers=4, pin_memory=True)\n",
    "\n",
    "data_loaders = {\"train\": train_loader, \"test\": test_loader, \"validation\": validation_loader}\n",
    "dataset_sizes = {\"train\": train_size, \"test\": test_size, \"validation\": validation_size}\n",
    "print(dataset_sizes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "71826738",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implementation from (with modifications): \n",
    "# https://github.com/pytorch/vision/blob/6db1569c89094cf23f3bc41f79275c45e9fcb3f3/torchvision/models/densenet.py#L126\n",
    "\n",
    "class _DenseLayer(nn.Module):\n",
    "    def __init__(self, num_input_features, growth_rate, bn_size):\n",
    "        super(_DenseLayer, self).__init__()\n",
    "        self.add_module('norm1', nn.BatchNorm2d(num_input_features)),\n",
    "        self.add_module('relu1', nn.ReLU(inplace=True)),\n",
    "        self.add_module('conv1', nn.Conv2d(num_input_features, bn_size *\n",
    "                                           growth_rate, kernel_size=1, stride=1,\n",
    "                                           bias=False)),\n",
    "        self.add_module('norm2', nn.BatchNorm2d(bn_size * growth_rate)),\n",
    "        self.add_module('relu2', nn.ReLU(inplace=True)),\n",
    "        self.add_module('conv2', nn.Conv2d(bn_size * growth_rate, growth_rate,\n",
    "                                           kernel_size=3, stride=1, padding=1,\n",
    "                                           bias=False)),\n",
    "\n",
    "    def bn_function(self, inputs):\n",
    "        # type: (List[Tensor]) -> Tensor\n",
    "        concated_features = torch.cat(inputs, 1)\n",
    "        bottleneck_output = self.conv1(self.relu1(self.norm1(concated_features)))  # noqa: T484\n",
    "        return bottleneck_output\n",
    "\n",
    "    # todo: rewrite when torchscript supports any\n",
    "    def any_requires_grad(self, input):\n",
    "        # type: (List[Tensor]) -> bool\n",
    "        for tensor in input:\n",
    "            if tensor.requires_grad:\n",
    "                return True\n",
    "        return False\n",
    "\n",
    "\n",
    "    # torchscript does not yet support *args, so we overload method\n",
    "    # allowing it to take either a List[Tensor] or single Tensor\n",
    "    def forward(self, input):  # noqa: F811\n",
    "        if isinstance(input, Tensor):\n",
    "            prev_features = [input]\n",
    "        else:\n",
    "            prev_features = input\n",
    "\n",
    "        bottleneck_output = self.bn_function(prev_features)\n",
    "\n",
    "        return self.conv2(self.relu2(self.norm2(bottleneck_output)))\n",
    "\n",
    "\n",
    "class _DenseBlock(nn.ModuleDict):\n",
    "    _version = 2\n",
    "\n",
    "    def __init__(self, num_layers, num_input_features, bn_size, growth_rate):\n",
    "        super(_DenseBlock, self).__init__()\n",
    "        for i in range(num_layers):\n",
    "            layer = _DenseLayer(\n",
    "                num_input_features + i * growth_rate,\n",
    "                growth_rate=growth_rate,\n",
    "                bn_size=bn_size\n",
    "            )\n",
    "            self.add_module('denselayer%d' % (i + 1), layer)\n",
    "\n",
    "    def forward(self, init_features):\n",
    "        features = [init_features]\n",
    "        for name, layer in self.items():\n",
    "            new_features = layer(features)\n",
    "            features.append(new_features)\n",
    "        return torch.cat(features, 1)\n",
    "\n",
    "\n",
    "class _Transition(nn.Sequential):\n",
    "    def __init__(self, num_input_features, num_output_features):\n",
    "        super(_Transition, self).__init__()\n",
    "        self.add_module('norm', nn.BatchNorm2d(num_input_features))\n",
    "        self.add_module('relu', nn.ReLU(inplace=True))\n",
    "        self.add_module('conv', nn.Conv2d(num_input_features, num_output_features,\n",
    "                                          kernel_size=1, stride=1, bias=False))\n",
    "        self.add_module('pool', nn.AvgPool2d(kernel_size=2, stride=2))\n",
    "\n",
    "\n",
    "class DenseNet(nn.Module):\n",
    "    r\"\"\"Densenet-BC model class, based on\n",
    "    `\"Densely Connected Convolutional Networks\" <https://arxiv.org/pdf/1608.06993.pdf>`_\n",
    "    Args:\n",
    "        growth_rate (int) - how many filters to add each layer (`k` in paper)\n",
    "        block_config (list of 4 ints) - how many layers in each pooling block\n",
    "        num_init_features (int) - the number of filters to learn in the first convolution layer\n",
    "        bn_size (int) - multiplicative factor for number of bottle neck layers\n",
    "          (i.e. bn_size * k features in the bottleneck layer)\n",
    "        num_classes (int) - number of classification classes\n",
    "          but slower. Default: *False*. See `\"paper\" <https://arxiv.org/pdf/1707.06990.pdf>`_\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, growth_rate=32, block_config=(6, 12, 24, 16),\n",
    "                 num_init_features=64, bn_size=4, num_classes=1000):\n",
    "\n",
    "        super(DenseNet, self).__init__()\n",
    "\n",
    "        # First convolution\n",
    "        # Modified from the original DenseNet implementation to mimic Resnet settings on CIFAR\n",
    "        self.features = nn.Sequential(OrderedDict([\n",
    "            ('conv0', nn.Conv2d(3, num_init_features, kernel_size=3, stride=1,\n",
    "                                padding='same', bias=False)),\n",
    "            ('norm0', nn.BatchNorm2d(num_init_features)),\n",
    "            ('relu0', nn.ReLU(inplace=True))\n",
    "        ]))\n",
    "\n",
    "        # Each denseblock\n",
    "        num_features = num_init_features\n",
    "        for i, num_layers in enumerate(block_config):\n",
    "            block = _DenseBlock(\n",
    "                num_layers=num_layers,\n",
    "                num_input_features=num_features,\n",
    "                bn_size=bn_size,\n",
    "                growth_rate=growth_rate\n",
    "            )\n",
    "            self.features.add_module('denseblock%d' % (i + 1), block)\n",
    "            num_features = num_features + num_layers * growth_rate\n",
    "            if i != len(block_config) - 1:\n",
    "                trans = _Transition(num_input_features=num_features,\n",
    "                                    num_output_features=num_features // 2)\n",
    "                self.features.add_module('transition%d' % (i + 1), trans)\n",
    "                num_features = num_features // 2\n",
    "\n",
    "        # Final batch norm\n",
    "        self.features.add_module('norm5', nn.BatchNorm2d(num_features))\n",
    "\n",
    "        # Linear layer\n",
    "        self.classifier = nn.Linear(num_features, num_classes)\n",
    "\n",
    "        # Official init from torch repo.\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight)\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "            elif isinstance(m, nn.Linear):\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        features = self.features(x)\n",
    "        out = F.relu(features, inplace=True)\n",
    "        out = F.adaptive_avg_pool2d(out, (1, 1))\n",
    "        out = torch.flatten(out, 1)\n",
    "        out = self.classifier(out)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2826bdb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Number of Parameters: 771228\n"
     ]
    }
   ],
   "source": [
    "#### Train Configurations, based on DSNet and ResNet paper\n",
    "model_n = 8\n",
    "epochs = 100 ### should be 180\n",
    "milestones = [int(epochs*0.5), int(epochs*0.75)]\n",
    "momentum = 0.9\n",
    "weight_decay = 0.0001\n",
    "gamma = 0.1\n",
    "lr = 0.1\n",
    "\n",
    "model = DenseNet(growth_rate=16, block_config=(2 * model_n, 2 * model_n, 2 * model_n),\n",
    "                 num_init_features=16, bn_size=2, num_classes=100)\n",
    "\n",
    "model.to(device)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=lr, momentum=momentum)\n",
    "scheduler = optim.lr_scheduler.MultiStepLR(optimizer, milestones=milestones, gamma=gamma)\n",
    "\n",
    "# summary(model, (3, 32, 32))\n",
    "print('Total Number of Parameters:', sum(p.numel() for p in model.parameters()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "16265b1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuration:  model:DenseNet  model_n: 3  batch size: 32  optimizer:SGD  lr: 0.1  epochs: 100\n",
      "----------------------------- Train --------------------------------\n",
      "Epoch 1/100\n",
      "------------------------------\n",
      "{'time': 52.19063, 'train_loss': 3.85947, 'train_acc': 0.1021, 'val_loss': 3.54879, 'val_acc': 0.1582}\n",
      "Epoch 2/100\n",
      "------------------------------\n",
      "{'time': 56.99864, 'train_loss': 3.18135, 'train_acc': 0.21472, 'val_loss': 2.79594, 'val_acc': 0.2902}\n",
      "Epoch 3/100\n",
      "------------------------------\n",
      "{'time': 50.74312, 'train_loss': 2.65927, 'train_acc': 0.31388, 'val_loss': 2.45695, 'val_acc': 0.3634}\n",
      "Epoch 4/100\n",
      "------------------------------\n",
      "{'time': 50.92215, 'train_loss': 2.33018, 'train_acc': 0.384, 'val_loss': 2.20637, 'val_acc': 0.417}\n",
      "Epoch 5/100\n",
      "------------------------------\n",
      "{'time': 50.85698, 'train_loss': 2.1224, 'train_acc': 0.4294, 'val_loss': 2.04856, 'val_acc': 0.444}\n",
      "Epoch 6/100\n",
      "------------------------------\n",
      "{'time': 50.48864, 'train_loss': 1.96578, 'train_acc': 0.4653, 'val_loss': 1.92926, 'val_acc': 0.4802}\n",
      "Epoch 7/100\n",
      "------------------------------\n",
      "{'time': 50.90829, 'train_loss': 1.85848, 'train_acc': 0.49094, 'val_loss': 1.87412, 'val_acc': 0.4918}\n",
      "Epoch 8/100\n",
      "------------------------------\n",
      "{'time': 55.74907, 'train_loss': 1.75825, 'train_acc': 0.51446, 'val_loss': 1.78808, 'val_acc': 0.5192}\n",
      "Epoch 9/100\n",
      "------------------------------\n",
      "{'time': 53.74897, 'train_loss': 1.68873, 'train_acc': 0.53014, 'val_loss': 1.71123, 'val_acc': 0.5336}\n",
      "Epoch 10/100\n",
      "------------------------------\n",
      "{'time': 52.24702, 'train_loss': 1.61969, 'train_acc': 0.54792, 'val_loss': 1.67866, 'val_acc': 0.5362}\n",
      "Epoch 11/100\n",
      "------------------------------\n",
      "{'time': 52.279, 'train_loss': 1.56462, 'train_acc': 0.56102, 'val_loss': 1.62704, 'val_acc': 0.5452}\n",
      "Epoch 12/100\n",
      "------------------------------\n",
      "{'time': 52.73205, 'train_loss': 1.51024, 'train_acc': 0.57342, 'val_loss': 1.62264, 'val_acc': 0.5594}\n",
      "Epoch 13/100\n",
      "------------------------------\n",
      "{'time': 52.26984, 'train_loss': 1.46423, 'train_acc': 0.58642, 'val_loss': 1.64187, 'val_acc': 0.554}\n",
      "Epoch 14/100\n",
      "------------------------------\n",
      "{'time': 51.23127, 'train_loss': 1.42666, 'train_acc': 0.59646, 'val_loss': 1.50098, 'val_acc': 0.583}\n",
      "Epoch 15/100\n",
      "------------------------------\n",
      "{'time': 51.80498, 'train_loss': 1.37876, 'train_acc': 0.60826, 'val_loss': 1.54149, 'val_acc': 0.5824}\n",
      "Epoch 16/100\n",
      "------------------------------\n",
      "{'time': 52.15287, 'train_loss': 1.35455, 'train_acc': 0.61388, 'val_loss': 1.46891, 'val_acc': 0.585}\n",
      "Epoch 17/100\n",
      "------------------------------\n",
      "{'time': 52.86521, 'train_loss': 1.32227, 'train_acc': 0.6232, 'val_loss': 1.49657, 'val_acc': 0.59}\n",
      "Epoch 18/100\n",
      "------------------------------\n",
      "{'time': 51.72141, 'train_loss': 1.28721, 'train_acc': 0.63058, 'val_loss': 1.49041, 'val_acc': 0.5902}\n",
      "Epoch 19/100\n",
      "------------------------------\n",
      "{'time': 55.02734, 'train_loss': 1.25711, 'train_acc': 0.63856, 'val_loss': 1.47695, 'val_acc': 0.5916}\n",
      "Epoch 20/100\n",
      "------------------------------\n",
      "{'time': 51.28629, 'train_loss': 1.23036, 'train_acc': 0.64606, 'val_loss': 1.42902, 'val_acc': 0.6024}\n",
      "Epoch 21/100\n",
      "------------------------------\n",
      "{'time': 51.01189, 'train_loss': 1.21703, 'train_acc': 0.6478, 'val_loss': 1.4498, 'val_acc': 0.604}\n",
      "Epoch 22/100\n",
      "------------------------------\n",
      "{'time': 51.48263, 'train_loss': 1.18722, 'train_acc': 0.65456, 'val_loss': 1.42693, 'val_acc': 0.6078}\n",
      "Epoch 23/100\n",
      "------------------------------\n",
      "{'time': 51.08194, 'train_loss': 1.17141, 'train_acc': 0.65782, 'val_loss': 1.42785, 'val_acc': 0.6104}\n",
      "Epoch 24/100\n",
      "------------------------------\n",
      "{'time': 51.35566, 'train_loss': 1.15792, 'train_acc': 0.66314, 'val_loss': 1.3672, 'val_acc': 0.6166}\n",
      "Epoch 25/100\n",
      "------------------------------\n",
      "{'time': 54.96768, 'train_loss': 1.13255, 'train_acc': 0.6694, 'val_loss': 1.43093, 'val_acc': 0.6124}\n",
      "Epoch 26/100\n",
      "------------------------------\n",
      "{'time': 51.96759, 'train_loss': 1.10681, 'train_acc': 0.67662, 'val_loss': 1.43232, 'val_acc': 0.595}\n",
      "Epoch 27/100\n",
      "------------------------------\n",
      "{'time': 51.71673, 'train_loss': 1.08943, 'train_acc': 0.68058, 'val_loss': 1.37751, 'val_acc': 0.6184}\n",
      "Epoch 28/100\n",
      "------------------------------\n",
      "{'time': 52.16157, 'train_loss': 1.08224, 'train_acc': 0.6829, 'val_loss': 1.39997, 'val_acc': 0.6152}\n",
      "Epoch 29/100\n",
      "------------------------------\n",
      "{'time': 52.18723, 'train_loss': 1.06041, 'train_acc': 0.68794, 'val_loss': 1.37952, 'val_acc': 0.621}\n",
      "Epoch 30/100\n",
      "------------------------------\n",
      "{'time': 54.04456, 'train_loss': 1.05681, 'train_acc': 0.68736, 'val_loss': 1.39651, 'val_acc': 0.6222}\n",
      "Epoch 31/100\n",
      "------------------------------\n",
      "{'time': 51.95781, 'train_loss': 1.03514, 'train_acc': 0.69374, 'val_loss': 1.38747, 'val_acc': 0.626}\n",
      "Epoch 32/100\n",
      "------------------------------\n",
      "{'time': 51.9805, 'train_loss': 1.02282, 'train_acc': 0.69858, 'val_loss': 1.38594, 'val_acc': 0.6286}\n",
      "Epoch 33/100\n",
      "------------------------------\n",
      "{'time': 51.49839, 'train_loss': 1.01046, 'train_acc': 0.70086, 'val_loss': 1.37139, 'val_acc': 0.623}\n",
      "Epoch 34/100\n",
      "------------------------------\n",
      "{'time': 52.14131, 'train_loss': 0.99313, 'train_acc': 0.70628, 'val_loss': 1.36755, 'val_acc': 0.622}\n",
      "Epoch 35/100\n",
      "------------------------------\n",
      "{'time': 51.40209, 'train_loss': 0.98362, 'train_acc': 0.7094, 'val_loss': 1.34421, 'val_acc': 0.6282}\n",
      "Epoch 36/100\n",
      "------------------------------\n",
      "{'time': 54.37276, 'train_loss': 0.98014, 'train_acc': 0.70856, 'val_loss': 1.33554, 'val_acc': 0.634}\n",
      "Epoch 37/100\n",
      "------------------------------\n",
      "{'time': 50.82201, 'train_loss': 0.96555, 'train_acc': 0.71236, 'val_loss': 1.35057, 'val_acc': 0.6366}\n",
      "Epoch 38/100\n",
      "------------------------------\n",
      "{'time': 50.91526, 'train_loss': 0.95256, 'train_acc': 0.71468, 'val_loss': 1.40118, 'val_acc': 0.63}\n",
      "Epoch 39/100\n",
      "------------------------------\n",
      "{'time': 49.79919, 'train_loss': 0.9383, 'train_acc': 0.71998, 'val_loss': 1.36554, 'val_acc': 0.628}\n",
      "Epoch 40/100\n",
      "------------------------------\n",
      "{'time': 51.23577, 'train_loss': 0.9272, 'train_acc': 0.72004, 'val_loss': 1.37253, 'val_acc': 0.6292}\n",
      "Epoch 41/100\n",
      "------------------------------\n",
      "{'time': 51.29115, 'train_loss': 0.91937, 'train_acc': 0.7227, 'val_loss': 1.3579, 'val_acc': 0.6344}\n",
      "Epoch 42/100\n",
      "------------------------------\n",
      "{'time': 52.43729, 'train_loss': 0.91828, 'train_acc': 0.72332, 'val_loss': 1.37293, 'val_acc': 0.6268}\n",
      "Epoch 43/100\n",
      "------------------------------\n",
      "{'time': 52.09906, 'train_loss': 0.90993, 'train_acc': 0.72626, 'val_loss': 1.3466, 'val_acc': 0.6398}\n",
      "Epoch 44/100\n",
      "------------------------------\n",
      "{'time': 51.14695, 'train_loss': 0.89423, 'train_acc': 0.73066, 'val_loss': 1.4092, 'val_acc': 0.6326}\n",
      "Epoch 45/100\n",
      "------------------------------\n",
      "{'time': 51.25032, 'train_loss': 0.88246, 'train_acc': 0.7353, 'val_loss': 1.3694, 'val_acc': 0.6298}\n",
      "Epoch 46/100\n",
      "------------------------------\n",
      "{'time': 50.47861, 'train_loss': 0.87684, 'train_acc': 0.73446, 'val_loss': 1.35731, 'val_acc': 0.631}\n",
      "Epoch 47/100\n",
      "------------------------------\n",
      "{'time': 52.08287, 'train_loss': 0.8701, 'train_acc': 0.7377, 'val_loss': 1.38361, 'val_acc': 0.639}\n",
      "Epoch 48/100\n",
      "------------------------------\n",
      "{'time': 53.45415, 'train_loss': 0.86273, 'train_acc': 0.7398, 'val_loss': 1.3457, 'val_acc': 0.6412}\n",
      "Epoch 49/100\n",
      "------------------------------\n",
      "{'time': 51.48184, 'train_loss': 0.85603, 'train_acc': 0.7408, 'val_loss': 1.42405, 'val_acc': 0.6192}\n",
      "Epoch 50/100\n",
      "------------------------------\n",
      "{'time': 53.47209, 'train_loss': 0.83731, 'train_acc': 0.74598, 'val_loss': 1.35549, 'val_acc': 0.6396}\n",
      "Epoch 51/100\n",
      "------------------------------\n",
      "{'time': 50.41208, 'train_loss': 0.67491, 'train_acc': 0.7955, 'val_loss': 1.23229, 'val_acc': 0.669}\n",
      "Epoch 52/100\n",
      "------------------------------\n",
      "{'time': 50.93446, 'train_loss': 0.62862, 'train_acc': 0.80826, 'val_loss': 1.23663, 'val_acc': 0.674}\n",
      "Epoch 53/100\n",
      "------------------------------\n",
      "{'time': 51.58656, 'train_loss': 0.61829, 'train_acc': 0.81066, 'val_loss': 1.23508, 'val_acc': 0.6722}\n",
      "Epoch 54/100\n",
      "------------------------------\n",
      "{'time': 51.07466, 'train_loss': 0.60314, 'train_acc': 0.81436, 'val_loss': 1.25883, 'val_acc': 0.6694}\n",
      "Epoch 55/100\n",
      "------------------------------\n",
      "{'time': 49.97772, 'train_loss': 0.59877, 'train_acc': 0.81746, 'val_loss': 1.24979, 'val_acc': 0.6734}\n",
      "Epoch 56/100\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'time': 53.62423, 'train_loss': 0.58722, 'train_acc': 0.81952, 'val_loss': 1.25875, 'val_acc': 0.6718}\n",
      "Epoch 57/100\n",
      "------------------------------\n",
      "{'time': 50.28523, 'train_loss': 0.57894, 'train_acc': 0.82018, 'val_loss': 1.25995, 'val_acc': 0.674}\n",
      "Epoch 58/100\n",
      "------------------------------\n",
      "{'time': 51.42764, 'train_loss': 0.5793, 'train_acc': 0.82048, 'val_loss': 1.28879, 'val_acc': 0.6684}\n",
      "Epoch 59/100\n",
      "------------------------------\n",
      "{'time': 51.82786, 'train_loss': 0.57338, 'train_acc': 0.8237, 'val_loss': 1.27279, 'val_acc': 0.6788}\n",
      "Epoch 60/100\n",
      "------------------------------\n",
      "{'time': 50.79615, 'train_loss': 0.56608, 'train_acc': 0.82654, 'val_loss': 1.28329, 'val_acc': 0.674}\n",
      "Epoch 61/100\n",
      "------------------------------\n",
      "{'time': 51.74843, 'train_loss': 0.56578, 'train_acc': 0.82378, 'val_loss': 1.27563, 'val_acc': 0.6744}\n",
      "Epoch 62/100\n",
      "------------------------------\n",
      "{'time': 58.88578, 'train_loss': 0.56257, 'train_acc': 0.82702, 'val_loss': 1.26969, 'val_acc': 0.6758}\n",
      "Epoch 63/100\n",
      "------------------------------\n",
      "{'time': 49.84419, 'train_loss': 0.55625, 'train_acc': 0.82862, 'val_loss': 1.27409, 'val_acc': 0.6714}\n",
      "Epoch 64/100\n",
      "------------------------------\n",
      "{'time': 50.92454, 'train_loss': 0.54973, 'train_acc': 0.83092, 'val_loss': 1.28633, 'val_acc': 0.6728}\n",
      "Epoch 65/100\n",
      "------------------------------\n",
      "{'time': 49.34347, 'train_loss': 0.5539, 'train_acc': 0.8269, 'val_loss': 1.27824, 'val_acc': 0.6776}\n",
      "Epoch 66/100\n",
      "------------------------------\n",
      "{'time': 44.42321, 'train_loss': 0.55292, 'train_acc': 0.82644, 'val_loss': 1.30462, 'val_acc': 0.673}\n",
      "Epoch 67/100\n",
      "------------------------------\n",
      "{'time': 44.56219, 'train_loss': 0.54976, 'train_acc': 0.82936, 'val_loss': 1.30763, 'val_acc': 0.6718}\n",
      "Epoch 68/100\n",
      "------------------------------\n",
      "{'time': 47.84386, 'train_loss': 0.54212, 'train_acc': 0.83142, 'val_loss': 1.30946, 'val_acc': 0.6756}\n",
      "Epoch 69/100\n",
      "------------------------------\n",
      "{'time': 45.72576, 'train_loss': 0.54239, 'train_acc': 0.83128, 'val_loss': 1.31358, 'val_acc': 0.6676}\n",
      "Epoch 70/100\n",
      "------------------------------\n",
      "{'time': 46.23775, 'train_loss': 0.53598, 'train_acc': 0.83278, 'val_loss': 1.30855, 'val_acc': 0.6688}\n",
      "Epoch 71/100\n",
      "------------------------------\n",
      "{'time': 44.9427, 'train_loss': 0.53636, 'train_acc': 0.83212, 'val_loss': 1.32476, 'val_acc': 0.6764}\n",
      "Epoch 72/100\n",
      "------------------------------\n",
      "{'time': 45.48016, 'train_loss': 0.53251, 'train_acc': 0.83458, 'val_loss': 1.30721, 'val_acc': 0.6704}\n",
      "Epoch 73/100\n",
      "------------------------------\n",
      "{'time': 45.0943, 'train_loss': 0.52969, 'train_acc': 0.8348, 'val_loss': 1.31411, 'val_acc': 0.6762}\n",
      "Epoch 74/100\n",
      "------------------------------\n",
      "{'time': 44.80982, 'train_loss': 0.52734, 'train_acc': 0.83444, 'val_loss': 1.31903, 'val_acc': 0.672}\n",
      "Epoch 75/100\n",
      "------------------------------\n",
      "{'time': 47.83993, 'train_loss': 0.52852, 'train_acc': 0.834, 'val_loss': 1.33649, 'val_acc': 0.672}\n",
      "Epoch 76/100\n",
      "------------------------------\n",
      "{'time': 45.56863, 'train_loss': 0.50798, 'train_acc': 0.8426, 'val_loss': 1.30923, 'val_acc': 0.6692}\n",
      "Epoch 77/100\n",
      "------------------------------\n",
      "{'time': 44.56546, 'train_loss': 0.50232, 'train_acc': 0.84164, 'val_loss': 1.31729, 'val_acc': 0.673}\n",
      "Epoch 78/100\n",
      "------------------------------\n",
      "{'time': 45.70411, 'train_loss': 0.50192, 'train_acc': 0.84268, 'val_loss': 1.30577, 'val_acc': 0.6702}\n",
      "Epoch 79/100\n",
      "------------------------------\n",
      "{'time': 44.57478, 'train_loss': 0.50307, 'train_acc': 0.84108, 'val_loss': 1.32693, 'val_acc': 0.6692}\n",
      "Epoch 80/100\n",
      "------------------------------\n",
      "{'time': 46.52049, 'train_loss': 0.50126, 'train_acc': 0.84464, 'val_loss': 1.31952, 'val_acc': 0.6712}\n",
      "Epoch 81/100\n",
      "------------------------------\n",
      "{'time': 45.87383, 'train_loss': 0.49955, 'train_acc': 0.84312, 'val_loss': 1.32851, 'val_acc': 0.671}\n",
      "Epoch 82/100\n",
      "------------------------------\n",
      "{'time': 49.0862, 'train_loss': 0.49409, 'train_acc': 0.84554, 'val_loss': 1.3187, 'val_acc': 0.6692}\n",
      "Epoch 83/100\n",
      "------------------------------\n",
      "{'time': 44.68612, 'train_loss': 0.49816, 'train_acc': 0.84404, 'val_loss': 1.32616, 'val_acc': 0.6718}\n",
      "Epoch 84/100\n",
      "------------------------------\n",
      "{'time': 44.47121, 'train_loss': 0.49672, 'train_acc': 0.84474, 'val_loss': 1.33912, 'val_acc': 0.6748}\n",
      "Epoch 85/100\n",
      "------------------------------\n",
      "{'time': 45.1102, 'train_loss': 0.49928, 'train_acc': 0.84518, 'val_loss': 1.35121, 'val_acc': 0.6706}\n",
      "Epoch 86/100\n",
      "------------------------------\n",
      "{'time': 45.03304, 'train_loss': 0.49672, 'train_acc': 0.84318, 'val_loss': 1.29554, 'val_acc': 0.677}\n",
      "Epoch 87/100\n",
      "------------------------------\n",
      "{'time': 44.51352, 'train_loss': 0.49593, 'train_acc': 0.84394, 'val_loss': 1.31171, 'val_acc': 0.673}\n",
      "Epoch 88/100\n",
      "------------------------------\n",
      "{'time': 44.43766, 'train_loss': 0.49751, 'train_acc': 0.84474, 'val_loss': 1.31103, 'val_acc': 0.6812}\n",
      "Epoch 89/100\n",
      "------------------------------\n",
      "{'time': 54.54857, 'train_loss': 0.4941, 'train_acc': 0.8465, 'val_loss': 1.30998, 'val_acc': 0.6742}\n",
      "Epoch 90/100\n",
      "------------------------------\n",
      "{'time': 52.89094, 'train_loss': 0.49937, 'train_acc': 0.84356, 'val_loss': 1.31621, 'val_acc': 0.6786}\n",
      "Epoch 91/100\n",
      "------------------------------\n",
      "{'time': 53.23224, 'train_loss': 0.49863, 'train_acc': 0.84292, 'val_loss': 1.33211, 'val_acc': 0.6712}\n",
      "Epoch 92/100\n",
      "------------------------------\n",
      "{'time': 52.80496, 'train_loss': 0.49337, 'train_acc': 0.84416, 'val_loss': 1.3104, 'val_acc': 0.6754}\n",
      "Epoch 93/100\n",
      "------------------------------\n",
      "{'time': 52.9624, 'train_loss': 0.49548, 'train_acc': 0.84562, 'val_loss': 1.31788, 'val_acc': 0.6766}\n",
      "Epoch 94/100\n",
      "------------------------------\n",
      "{'time': 53.82254, 'train_loss': 0.48756, 'train_acc': 0.84644, 'val_loss': 1.29162, 'val_acc': 0.678}\n",
      "Epoch 95/100\n",
      "------------------------------\n",
      "{'time': 55.34955, 'train_loss': 0.49245, 'train_acc': 0.84498, 'val_loss': 1.34215, 'val_acc': 0.6712}\n",
      "Epoch 96/100\n",
      "------------------------------\n",
      "{'time': 53.35583, 'train_loss': 0.4906, 'train_acc': 0.84652, 'val_loss': 1.33611, 'val_acc': 0.6752}\n",
      "Epoch 97/100\n",
      "------------------------------\n",
      "{'time': 54.01474, 'train_loss': 0.49233, 'train_acc': 0.84504, 'val_loss': 1.32868, 'val_acc': 0.6734}\n",
      "Epoch 98/100\n",
      "------------------------------\n",
      "{'time': 53.49504, 'train_loss': 0.49405, 'train_acc': 0.84686, 'val_loss': 1.30984, 'val_acc': 0.6748}\n",
      "Epoch 99/100\n",
      "------------------------------\n",
      "{'time': 52.78964, 'train_loss': 0.49272, 'train_acc': 0.84574, 'val_loss': 1.34235, 'val_acc': 0.67}\n",
      "Epoch 100/100\n",
      "------------------------------\n",
      "{'time': 51.88587, 'train_loss': 0.49081, 'train_acc': 0.846, 'val_loss': 1.33778, 'val_acc': 0.6716}\n",
      "----------------------------- Test --------------------------------\n",
      "{'time': 53.8259, 'test_loss': 1.3569, 'test_acc': 0.6688}\n"
     ]
    }
   ],
   "source": [
    "### Train loop + validation/ also test at the end\n",
    "print(\"Configuration: \", \"model:DenseNet\", \" model_n:\", model_n, \" batch size:\", batch_size, \n",
    "      \" optimizer:SGD\", \" lr:\", lr, \" epochs:\", epochs)\n",
    "\n",
    "all_epoch_loss = {\"train\": [], \"validation\": []}\n",
    "all_epoch_acc = {\"train\":  [], \"validation\": []}\n",
    "\n",
    "print(\"----------------------------- Train --------------------------------\")\n",
    "for epoch in range(epochs):\n",
    "    start_time = time.time()\n",
    "    print(\"Epoch {}/{}\".format(epoch+1, epochs))\n",
    "    print(\"-\" * 30)\n",
    "    \n",
    "    \n",
    "    epoch_loss = {\"train\": 0.0, \"validation\": 0.0}\n",
    "    epoch_acc = {\"train\": 0.0, \"validation\": 0.0}\n",
    "    \n",
    "    running_loss = {\"train\": 0.0, \"validation\": 0.0}\n",
    "    running_corrects = {\"train\": 0, \"validation\": 0}\n",
    "    \n",
    "    for phase in [\"train\", \"validation\"]:\n",
    "        if phase == \"train\":\n",
    "            model.train(True)\n",
    "        else:\n",
    "            model.train(False)\n",
    "        \n",
    "        for data in data_loaders[phase]:\n",
    "            inputs, labels = data \n",
    "            \n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            optimizer.zero_grad() # clear all gradients\n",
    "            \n",
    "            outputs = model(inputs) # batch_size x num_classes\n",
    "            _, preds = torch.max(outputs.data, 1) # values, indices\n",
    "            loss = loss_fn(outputs, labels)\n",
    "            \n",
    "            if phase == \"train\":\n",
    "                loss.backward()  # compute gradients\n",
    "                optimizer.step() # update weights/biases\n",
    "               \n",
    "            running_loss[phase] += loss.data.item() * inputs.size(0)\n",
    "            running_corrects[phase] += torch.sum(preds == labels.data).item()\n",
    "        \n",
    "        all_epoch_loss[phase].append(running_loss[phase] / dataset_sizes[phase])\n",
    "        all_epoch_acc[phase].append(running_corrects[phase] / dataset_sizes[phase])\n",
    "        \n",
    "        epoch_loss[phase] = running_loss[phase] / dataset_sizes[phase]\n",
    "        epoch_acc[phase] =  running_corrects[phase] / dataset_sizes[phase]\n",
    "\n",
    "    # Visualize the loss and accuracy values.\n",
    "    print({\n",
    "        'time': np.round(time.time()-start_time, 5),\n",
    "        'train_loss': np.round(epoch_loss[\"train\"], 5),\n",
    "        'train_acc': np.round(epoch_acc[\"train\"], 5),\n",
    "        'val_loss': np.round(epoch_loss[\"validation\"], 5),\n",
    "        'val_acc': np.round(epoch_acc[\"validation\"], 5),\n",
    "    })\n",
    "    \n",
    "    scheduler.step()\n",
    "\n",
    "    \n",
    "    \n",
    "with open('DenseNet_3_bs_32_opt_SGD_lr_1_epochs_100_loss.txt', 'w') as f_loss:\n",
    "    print(all_epoch_loss, file=f_loss)\n",
    "    \n",
    "with open('DenseNet_3_bs_32_opt_SGD_lr_1_epochs_100_acc.txt', 'w') as f_acc:\n",
    "    print(all_epoch_acc, file=f_acc)\n",
    "    \n",
    "### evaluating the model with test set\n",
    "print(\"----------------------------- Test --------------------------------\")\n",
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "    running_loss = 0\n",
    "    running_corrects = 0\n",
    "\n",
    "    for data in test_loader:\n",
    "        inputs, labels = data \n",
    "\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad() # clear all gradients\n",
    "\n",
    "        outputs = model(inputs) # batch_size x num_classes\n",
    "        _, preds = torch.max(outputs.data, 1) # values, indices\n",
    "        loss = loss_fn(outputs, labels)\n",
    "\n",
    "        running_loss += loss.data.item() * inputs.size(0)\n",
    "        running_corrects += torch.sum(preds == labels.data).item()\n",
    "\n",
    "    # Visualize the loss and accuracy values.\n",
    "    print({\n",
    "    'time': np.round(time.time()-start_time, 5),\n",
    "    'test_loss': np.round(running_loss/ dataset_sizes['test'], 5),\n",
    "    'test_acc': np.round(running_corrects/ dataset_sizes['test'], 5),\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28135f96",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7506e9b9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ecdb2381",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuration:  model:DenseNet  model_n: 8  batch size: 32  optimizer:SGD  lr: 0.1  epochs: 100\n",
      "----------------------------- Train --------------------------------\n",
      "Epoch 1/100\n",
      "------------------------------\n",
      "{'time': 99.05934, 'train_loss': 3.88425, 'train_acc': 0.10126, 'val_loss': 3.52518, 'val_acc': 0.1496}\n",
      "Epoch 2/100\n",
      "------------------------------\n",
      "{'time': 94.28528, 'train_loss': 3.05189, 'train_acc': 0.23892, 'val_loss': 2.7674, 'val_acc': 0.2902}\n",
      "Epoch 3/100\n",
      "------------------------------\n",
      "{'time': 93.84855, 'train_loss': 2.4272, 'train_acc': 0.36184, 'val_loss': 2.20881, 'val_acc': 0.4086}\n",
      "Epoch 4/100\n",
      "------------------------------\n",
      "{'time': 98.72011, 'train_loss': 2.06806, 'train_acc': 0.44188, 'val_loss': 1.86049, 'val_acc': 0.4874}\n",
      "Epoch 5/100\n",
      "------------------------------\n",
      "{'time': 93.03579, 'train_loss': 1.82793, 'train_acc': 0.49776, 'val_loss': 1.78385, 'val_acc': 0.5122}\n",
      "Epoch 6/100\n",
      "------------------------------\n",
      "{'time': 92.31454, 'train_loss': 1.65924, 'train_acc': 0.53634, 'val_loss': 1.6551, 'val_acc': 0.5468}\n",
      "Epoch 7/100\n",
      "------------------------------\n",
      "{'time': 96.62542, 'train_loss': 1.51451, 'train_acc': 0.57494, 'val_loss': 1.52416, 'val_acc': 0.5754}\n",
      "Epoch 8/100\n",
      "------------------------------\n",
      "{'time': 95.42908, 'train_loss': 1.40858, 'train_acc': 0.59984, 'val_loss': 1.49499, 'val_acc': 0.5822}\n",
      "Epoch 9/100\n",
      "------------------------------\n",
      "{'time': 97.76957, 'train_loss': 1.31425, 'train_acc': 0.62248, 'val_loss': 1.44339, 'val_acc': 0.6018}\n",
      "Epoch 10/100\n",
      "------------------------------\n",
      "{'time': 99.98494, 'train_loss': 1.23916, 'train_acc': 0.63992, 'val_loss': 1.43261, 'val_acc': 0.599}\n",
      "Epoch 11/100\n",
      "------------------------------\n",
      "{'time': 93.77609, 'train_loss': 1.17224, 'train_acc': 0.65858, 'val_loss': 1.39245, 'val_acc': 0.611}\n",
      "Epoch 12/100\n",
      "------------------------------\n",
      "{'time': 92.85758, 'train_loss': 1.11135, 'train_acc': 0.6748, 'val_loss': 1.35879, 'val_acc': 0.6304}\n",
      "Epoch 13/100\n",
      "------------------------------\n",
      "{'time': 93.65098, 'train_loss': 1.04746, 'train_acc': 0.69292, 'val_loss': 1.30382, 'val_acc': 0.632}\n",
      "Epoch 14/100\n",
      "------------------------------\n",
      "{'time': 97.15172, 'train_loss': 1.00162, 'train_acc': 0.70302, 'val_loss': 1.27737, 'val_acc': 0.6452}\n",
      "Epoch 15/100\n",
      "------------------------------\n",
      "{'time': 93.51289, 'train_loss': 0.95765, 'train_acc': 0.71486, 'val_loss': 1.29021, 'val_acc': 0.647}\n",
      "Epoch 16/100\n",
      "------------------------------\n",
      "{'time': 94.68663, 'train_loss': 0.91595, 'train_acc': 0.72886, 'val_loss': 1.23361, 'val_acc': 0.6598}\n",
      "Epoch 17/100\n",
      "------------------------------\n",
      "{'time': 98.71886, 'train_loss': 0.87313, 'train_acc': 0.73774, 'val_loss': 1.28757, 'val_acc': 0.6544}\n",
      "Epoch 18/100\n",
      "------------------------------\n",
      "{'time': 93.08696, 'train_loss': 0.84061, 'train_acc': 0.74518, 'val_loss': 1.2692, 'val_acc': 0.6576}\n",
      "Epoch 19/100\n",
      "------------------------------\n",
      "{'time': 91.82405, 'train_loss': 0.80803, 'train_acc': 0.75402, 'val_loss': 1.27933, 'val_acc': 0.6584}\n",
      "Epoch 20/100\n",
      "------------------------------\n",
      "{'time': 98.81096, 'train_loss': 0.77668, 'train_acc': 0.76382, 'val_loss': 1.22372, 'val_acc': 0.6708}\n",
      "Epoch 21/100\n",
      "------------------------------\n",
      "{'time': 95.55569, 'train_loss': 0.7411, 'train_acc': 0.77166, 'val_loss': 1.25505, 'val_acc': 0.669}\n",
      "Epoch 22/100\n",
      "------------------------------\n",
      "{'time': 95.71523, 'train_loss': 0.71516, 'train_acc': 0.77894, 'val_loss': 1.31628, 'val_acc': 0.6564}\n",
      "Epoch 23/100\n",
      "------------------------------\n",
      "{'time': 97.40603, 'train_loss': 0.69027, 'train_acc': 0.78728, 'val_loss': 1.30077, 'val_acc': 0.6618}\n",
      "Epoch 24/100\n",
      "------------------------------\n",
      "{'time': 93.03839, 'train_loss': 0.66354, 'train_acc': 0.79346, 'val_loss': 1.26803, 'val_acc': 0.6722}\n",
      "Epoch 25/100\n",
      "------------------------------\n",
      "{'time': 93.20936, 'train_loss': 0.64421, 'train_acc': 0.80098, 'val_loss': 1.31591, 'val_acc': 0.6642}\n",
      "Epoch 26/100\n",
      "------------------------------\n",
      "{'time': 93.02975, 'train_loss': 0.62116, 'train_acc': 0.80654, 'val_loss': 1.26155, 'val_acc': 0.672}\n",
      "Epoch 27/100\n",
      "------------------------------\n",
      "{'time': 98.84653, 'train_loss': 0.5951, 'train_acc': 0.81344, 'val_loss': 1.30699, 'val_acc': 0.6764}\n",
      "Epoch 28/100\n",
      "------------------------------\n",
      "{'time': 95.56502, 'train_loss': 0.57566, 'train_acc': 0.81786, 'val_loss': 1.29838, 'val_acc': 0.6756}\n",
      "Epoch 29/100\n",
      "------------------------------\n",
      "{'time': 97.61127, 'train_loss': 0.56227, 'train_acc': 0.81988, 'val_loss': 1.28811, 'val_acc': 0.6756}\n",
      "Epoch 30/100\n",
      "------------------------------\n",
      "{'time': 98.72606, 'train_loss': 0.5341, 'train_acc': 0.8307, 'val_loss': 1.29392, 'val_acc': 0.6744}\n",
      "Epoch 31/100\n",
      "------------------------------\n",
      "{'time': 92.53259, 'train_loss': 0.51501, 'train_acc': 0.83556, 'val_loss': 1.34281, 'val_acc': 0.6698}\n",
      "Epoch 32/100\n",
      "------------------------------\n",
      "{'time': 93.88059, 'train_loss': 0.49453, 'train_acc': 0.84116, 'val_loss': 1.32087, 'val_acc': 0.6788}\n",
      "Epoch 33/100\n",
      "------------------------------\n",
      "{'time': 98.33288, 'train_loss': 0.49025, 'train_acc': 0.84196, 'val_loss': 1.37561, 'val_acc': 0.6754}\n",
      "Epoch 34/100\n",
      "------------------------------\n",
      "{'time': 94.15839, 'train_loss': 0.47072, 'train_acc': 0.8475, 'val_loss': 1.36742, 'val_acc': 0.6722}\n",
      "Epoch 35/100\n",
      "------------------------------\n",
      "{'time': 94.25925, 'train_loss': 0.45814, 'train_acc': 0.85062, 'val_loss': 1.4023, 'val_acc': 0.6814}\n",
      "Epoch 36/100\n",
      "------------------------------\n",
      "{'time': 99.37608, 'train_loss': 0.43897, 'train_acc': 0.85804, 'val_loss': 1.38521, 'val_acc': 0.6706}\n",
      "Epoch 37/100\n",
      "------------------------------\n",
      "{'time': 91.95535, 'train_loss': 0.42758, 'train_acc': 0.8605, 'val_loss': 1.3493, 'val_acc': 0.6876}\n",
      "Epoch 38/100\n",
      "------------------------------\n",
      "{'time': 93.74599, 'train_loss': 0.4141, 'train_acc': 0.86582, 'val_loss': 1.4437, 'val_acc': 0.6778}\n",
      "Epoch 39/100\n",
      "------------------------------\n",
      "{'time': 94.12115, 'train_loss': 0.40519, 'train_acc': 0.8672, 'val_loss': 1.41743, 'val_acc': 0.6856}\n",
      "Epoch 40/100\n",
      "------------------------------\n",
      "{'time': 100.09845, 'train_loss': 0.39655, 'train_acc': 0.86932, 'val_loss': 1.40374, 'val_acc': 0.686}\n",
      "Epoch 41/100\n",
      "------------------------------\n",
      "{'time': 95.40831, 'train_loss': 0.37939, 'train_acc': 0.87418, 'val_loss': 1.39403, 'val_acc': 0.6818}\n",
      "Epoch 42/100\n",
      "------------------------------\n",
      "{'time': 96.06887, 'train_loss': 0.36992, 'train_acc': 0.87796, 'val_loss': 1.4869, 'val_acc': 0.6792}\n",
      "Epoch 43/100\n",
      "------------------------------\n",
      "{'time': 97.17829, 'train_loss': 0.35935, 'train_acc': 0.88246, 'val_loss': 1.44853, 'val_acc': 0.6846}\n",
      "Epoch 44/100\n",
      "------------------------------\n",
      "{'time': 94.30656, 'train_loss': 0.34676, 'train_acc': 0.8854, 'val_loss': 1.43546, 'val_acc': 0.6888}\n",
      "Epoch 45/100\n",
      "------------------------------\n",
      "{'time': 93.62821, 'train_loss': 0.33646, 'train_acc': 0.8875, 'val_loss': 1.46458, 'val_acc': 0.6788}\n",
      "Epoch 46/100\n",
      "------------------------------\n",
      "{'time': 98.11629, 'train_loss': 0.32818, 'train_acc': 0.89072, 'val_loss': 1.47133, 'val_acc': 0.6868}\n",
      "Epoch 47/100\n",
      "------------------------------\n",
      "{'time': 93.9697, 'train_loss': 0.31023, 'train_acc': 0.89836, 'val_loss': 1.43935, 'val_acc': 0.6846}\n",
      "Epoch 48/100\n",
      "------------------------------\n",
      "{'time': 95.43891, 'train_loss': 0.30436, 'train_acc': 0.8988, 'val_loss': 1.50956, 'val_acc': 0.6926}\n",
      "Epoch 49/100\n",
      "------------------------------\n",
      "{'time': 99.8835, 'train_loss': 0.30029, 'train_acc': 0.90098, 'val_loss': 1.53829, 'val_acc': 0.6802}\n",
      "Epoch 50/100\n",
      "------------------------------\n",
      "{'time': 92.23438, 'train_loss': 0.28895, 'train_acc': 0.90478, 'val_loss': 1.51878, 'val_acc': 0.6898}\n",
      "Epoch 51/100\n",
      "------------------------------\n",
      "{'time': 92.7189, 'train_loss': 0.16415, 'train_acc': 0.9473, 'val_loss': 1.36265, 'val_acc': 0.719}\n",
      "Epoch 52/100\n",
      "------------------------------\n",
      "{'time': 96.51625, 'train_loss': 0.12501, 'train_acc': 0.96158, 'val_loss': 1.34857, 'val_acc': 0.7298}\n",
      "Epoch 53/100\n",
      "------------------------------\n",
      "{'time': 94.92862, 'train_loss': 0.11218, 'train_acc': 0.96604, 'val_loss': 1.35667, 'val_acc': 0.7252}\n",
      "Epoch 54/100\n",
      "------------------------------\n",
      "{'time': 95.00708, 'train_loss': 0.10286, 'train_acc': 0.96902, 'val_loss': 1.36243, 'val_acc': 0.7236}\n",
      "Epoch 55/100\n",
      "------------------------------\n",
      "{'time': 93.8123, 'train_loss': 0.09787, 'train_acc': 0.97022, 'val_loss': 1.42072, 'val_acc': 0.721}\n",
      "Epoch 56/100\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'time': 96.75016, 'train_loss': 0.09206, 'train_acc': 0.97208, 'val_loss': 1.38779, 'val_acc': 0.7312}\n",
      "Epoch 57/100\n",
      "------------------------------\n",
      "{'time': 92.63182, 'train_loss': 0.08469, 'train_acc': 0.97506, 'val_loss': 1.39219, 'val_acc': 0.7306}\n",
      "Epoch 58/100\n",
      "------------------------------\n",
      "{'time': 91.4026, 'train_loss': 0.08568, 'train_acc': 0.97382, 'val_loss': 1.40717, 'val_acc': 0.7256}\n",
      "Epoch 59/100\n",
      "------------------------------\n",
      "{'time': 98.89914, 'train_loss': 0.07843, 'train_acc': 0.97708, 'val_loss': 1.43774, 'val_acc': 0.7222}\n",
      "Epoch 60/100\n",
      "------------------------------\n",
      "{'time': 95.61185, 'train_loss': 0.07745, 'train_acc': 0.9771, 'val_loss': 1.41178, 'val_acc': 0.7254}\n",
      "Epoch 61/100\n",
      "------------------------------\n",
      "{'time': 94.03176, 'train_loss': 0.07394, 'train_acc': 0.97786, 'val_loss': 1.46184, 'val_acc': 0.726}\n",
      "Epoch 62/100\n",
      "------------------------------\n",
      "{'time': 98.7251, 'train_loss': 0.07087, 'train_acc': 0.97892, 'val_loss': 1.48168, 'val_acc': 0.7224}\n",
      "Epoch 63/100\n",
      "------------------------------\n",
      "{'time': 92.56557, 'train_loss': 0.06907, 'train_acc': 0.98006, 'val_loss': 1.4566, 'val_acc': 0.7236}\n",
      "Epoch 64/100\n",
      "------------------------------\n",
      "{'time': 92.49918, 'train_loss': 0.06871, 'train_acc': 0.97958, 'val_loss': 1.45218, 'val_acc': 0.7244}\n",
      "Epoch 65/100\n",
      "------------------------------\n",
      "{'time': 97.58276, 'train_loss': 0.06566, 'train_acc': 0.98106, 'val_loss': 1.49152, 'val_acc': 0.7216}\n",
      "Epoch 66/100\n",
      "------------------------------\n",
      "{'time': 96.3988, 'train_loss': 0.06681, 'train_acc': 0.97976, 'val_loss': 1.48303, 'val_acc': 0.7298}\n",
      "Epoch 67/100\n",
      "------------------------------\n",
      "{'time': 94.54631, 'train_loss': 0.06295, 'train_acc': 0.9816, 'val_loss': 1.49912, 'val_acc': 0.7294}\n",
      "Epoch 68/100\n",
      "------------------------------\n",
      "{'time': 97.80586, 'train_loss': 0.06333, 'train_acc': 0.98076, 'val_loss': 1.50125, 'val_acc': 0.7314}\n",
      "Epoch 69/100\n",
      "------------------------------\n",
      "{'time': 98.55616, 'train_loss': 0.06109, 'train_acc': 0.98186, 'val_loss': 1.51533, 'val_acc': 0.7226}\n",
      "Epoch 70/100\n",
      "------------------------------\n",
      "{'time': 90.52729, 'train_loss': 0.0578, 'train_acc': 0.9835, 'val_loss': 1.5034, 'val_acc': 0.7208}\n",
      "Epoch 71/100\n",
      "------------------------------\n",
      "{'time': 93.30327, 'train_loss': 0.05818, 'train_acc': 0.98302, 'val_loss': 1.50558, 'val_acc': 0.726}\n",
      "Epoch 72/100\n",
      "------------------------------\n",
      "{'time': 98.61962, 'train_loss': 0.05886, 'train_acc': 0.9827, 'val_loss': 1.53109, 'val_acc': 0.722}\n",
      "Epoch 73/100\n",
      "------------------------------\n",
      "{'time': 96.77541, 'train_loss': 0.05529, 'train_acc': 0.98352, 'val_loss': 1.52325, 'val_acc': 0.728}\n",
      "Epoch 74/100\n",
      "------------------------------\n",
      "{'time': 93.85165, 'train_loss': 0.05286, 'train_acc': 0.9846, 'val_loss': 1.54496, 'val_acc': 0.7236}\n",
      "Epoch 75/100\n",
      "------------------------------\n",
      "{'time': 98.05416, 'train_loss': 0.05454, 'train_acc': 0.9842, 'val_loss': 1.55479, 'val_acc': 0.7252}\n",
      "Epoch 76/100\n",
      "------------------------------\n",
      "{'time': 93.56695, 'train_loss': 0.0488, 'train_acc': 0.98568, 'val_loss': 1.52297, 'val_acc': 0.7298}\n",
      "Epoch 77/100\n",
      "------------------------------\n",
      "{'time': 94.07609, 'train_loss': 0.04973, 'train_acc': 0.98536, 'val_loss': 1.54232, 'val_acc': 0.719}\n",
      "Epoch 78/100\n",
      "------------------------------\n",
      "{'time': 96.07507, 'train_loss': 0.04825, 'train_acc': 0.98666, 'val_loss': 1.52959, 'val_acc': 0.7274}\n",
      "Epoch 79/100\n",
      "------------------------------\n",
      "{'time': 95.3273, 'train_loss': 0.04926, 'train_acc': 0.98628, 'val_loss': 1.54996, 'val_acc': 0.7234}\n",
      "Epoch 80/100\n",
      "------------------------------\n",
      "{'time': 94.09939, 'train_loss': 0.05041, 'train_acc': 0.98572, 'val_loss': 1.55085, 'val_acc': 0.7248}\n",
      "Epoch 81/100\n",
      "------------------------------\n",
      "{'time': 94.95875, 'train_loss': 0.04791, 'train_acc': 0.98624, 'val_loss': 1.51294, 'val_acc': 0.727}\n",
      "Epoch 82/100\n",
      "------------------------------\n",
      "{'time': 97.06, 'train_loss': 0.04954, 'train_acc': 0.98568, 'val_loss': 1.54899, 'val_acc': 0.7228}\n",
      "Epoch 83/100\n",
      "------------------------------\n",
      "{'time': 93.5243, 'train_loss': 0.04785, 'train_acc': 0.9859, 'val_loss': 1.56473, 'val_acc': 0.7248}\n",
      "Epoch 84/100\n",
      "------------------------------\n",
      "{'time': 92.16749, 'train_loss': 0.04648, 'train_acc': 0.98696, 'val_loss': 1.52551, 'val_acc': 0.7354}\n",
      "Epoch 85/100\n",
      "------------------------------\n",
      "{'time': 99.24181, 'train_loss': 0.04576, 'train_acc': 0.98704, 'val_loss': 1.54424, 'val_acc': 0.723}\n",
      "Epoch 86/100\n",
      "------------------------------\n",
      "{'time': 94.4697, 'train_loss': 0.04744, 'train_acc': 0.9871, 'val_loss': 1.56131, 'val_acc': 0.7214}\n",
      "Epoch 87/100\n",
      "------------------------------\n",
      "{'time': 95.10791, 'train_loss': 0.04564, 'train_acc': 0.9877, 'val_loss': 1.54771, 'val_acc': 0.7262}\n",
      "Epoch 88/100\n",
      "------------------------------\n",
      "{'time': 99.89227, 'train_loss': 0.04625, 'train_acc': 0.98724, 'val_loss': 1.53989, 'val_acc': 0.7198}\n",
      "Epoch 89/100\n",
      "------------------------------\n",
      "{'time': 93.95275, 'train_loss': 0.04855, 'train_acc': 0.986, 'val_loss': 1.5578, 'val_acc': 0.7304}\n",
      "Epoch 90/100\n",
      "------------------------------\n",
      "{'time': 93.92365, 'train_loss': 0.0474, 'train_acc': 0.98616, 'val_loss': 1.52676, 'val_acc': 0.7334}\n",
      "Epoch 91/100\n",
      "------------------------------\n",
      "{'time': 98.17832, 'train_loss': 0.04632, 'train_acc': 0.98726, 'val_loss': 1.5506, 'val_acc': 0.7256}\n",
      "Epoch 92/100\n",
      "------------------------------\n",
      "{'time': 95.95312, 'train_loss': 0.04699, 'train_acc': 0.9871, 'val_loss': 1.53456, 'val_acc': 0.7284}\n",
      "Epoch 93/100\n",
      "------------------------------\n",
      "{'time': 95.64205, 'train_loss': 0.04565, 'train_acc': 0.98756, 'val_loss': 1.56001, 'val_acc': 0.7312}\n",
      "Epoch 94/100\n",
      "------------------------------\n",
      "{'time': 99.86175, 'train_loss': 0.0459, 'train_acc': 0.9871, 'val_loss': 1.55232, 'val_acc': 0.7204}\n",
      "Epoch 95/100\n",
      "------------------------------\n",
      "{'time': 93.58223, 'train_loss': 0.0436, 'train_acc': 0.98838, 'val_loss': 1.54667, 'val_acc': 0.7272}\n",
      "Epoch 96/100\n",
      "------------------------------\n",
      "{'time': 91.76497, 'train_loss': 0.04606, 'train_acc': 0.98764, 'val_loss': 1.54974, 'val_acc': 0.723}\n",
      "Epoch 97/100\n",
      "------------------------------\n",
      "{'time': 92.06275, 'train_loss': 0.0451, 'train_acc': 0.98706, 'val_loss': 1.54956, 'val_acc': 0.7272}\n",
      "Epoch 98/100\n",
      "------------------------------\n",
      "{'time': 97.99794, 'train_loss': 0.04571, 'train_acc': 0.98784, 'val_loss': 1.53701, 'val_acc': 0.7292}\n",
      "Epoch 99/100\n",
      "------------------------------\n",
      "{'time': 97.03582, 'train_loss': 0.04566, 'train_acc': 0.98672, 'val_loss': 1.55798, 'val_acc': 0.7286}\n",
      "Epoch 100/100\n",
      "------------------------------\n",
      "{'time': 93.91912, 'train_loss': 0.04445, 'train_acc': 0.98788, 'val_loss': 1.54298, 'val_acc': 0.7288}\n",
      "----------------------------- Test --------------------------------\n",
      "{'time': 97.06827, 'test_loss': 1.54835, 'test_acc': 0.7198}\n"
     ]
    }
   ],
   "source": [
    "### Train loop + validation/ also test at the end\n",
    "print(\"Configuration: \", \"model:DenseNet\", \" model_n:\", model_n, \" batch size:\", batch_size, \n",
    "      \" optimizer:SGD\", \" lr:\", lr, \" epochs:\", epochs)\n",
    "\n",
    "all_epoch_loss = {\"train\": [], \"validation\": []}\n",
    "all_epoch_acc = {\"train\":  [], \"validation\": []}\n",
    "\n",
    "print(\"----------------------------- Train --------------------------------\")\n",
    "for epoch in range(epochs):\n",
    "    start_time = time.time()\n",
    "    print(\"Epoch {}/{}\".format(epoch+1, epochs))\n",
    "    print(\"-\" * 30)\n",
    "    \n",
    "    \n",
    "    epoch_loss = {\"train\": 0.0, \"validation\": 0.0}\n",
    "    epoch_acc = {\"train\": 0.0, \"validation\": 0.0}\n",
    "    \n",
    "    running_loss = {\"train\": 0.0, \"validation\": 0.0}\n",
    "    running_corrects = {\"train\": 0, \"validation\": 0}\n",
    "    \n",
    "    for phase in [\"train\", \"validation\"]:\n",
    "        if phase == \"train\":\n",
    "            model.train(True)\n",
    "        else:\n",
    "            model.train(False)\n",
    "        \n",
    "        for data in data_loaders[phase]:\n",
    "            inputs, labels = data \n",
    "            \n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            optimizer.zero_grad() # clear all gradients\n",
    "            \n",
    "            outputs = model(inputs) # batch_size x num_classes\n",
    "            _, preds = torch.max(outputs.data, 1) # values, indices\n",
    "            loss = loss_fn(outputs, labels)\n",
    "            \n",
    "            if phase == \"train\":\n",
    "                loss.backward()  # compute gradients\n",
    "                optimizer.step() # update weights/biases\n",
    "               \n",
    "            running_loss[phase] += loss.data.item() * inputs.size(0)\n",
    "            running_corrects[phase] += torch.sum(preds == labels.data).item()\n",
    "        \n",
    "        all_epoch_loss[phase].append(running_loss[phase] / dataset_sizes[phase])\n",
    "        all_epoch_acc[phase].append(running_corrects[phase] / dataset_sizes[phase])\n",
    "        \n",
    "        epoch_loss[phase] = running_loss[phase] / dataset_sizes[phase]\n",
    "        epoch_acc[phase] =  running_corrects[phase] / dataset_sizes[phase]\n",
    "\n",
    "    # Visualize the loss and accuracy values.\n",
    "    print({\n",
    "        'time': np.round(time.time()-start_time, 5),\n",
    "        'train_loss': np.round(epoch_loss[\"train\"], 5),\n",
    "        'train_acc': np.round(epoch_acc[\"train\"], 5),\n",
    "        'val_loss': np.round(epoch_loss[\"validation\"], 5),\n",
    "        'val_acc': np.round(epoch_acc[\"validation\"], 5),\n",
    "    })\n",
    "    \n",
    "    scheduler.step()\n",
    "\n",
    "    \n",
    "    \n",
    "with open('DenseNet_8_bs_32_opt_SGD_lr_1_epochs_100_loss.txt', 'w') as f_loss:\n",
    "    print(all_epoch_loss, file=f_loss)\n",
    "    \n",
    "with open('DenseNet_8_bs_32_opt_SGD_lr_1_epochs_100_acc.txt', 'w') as f_acc:\n",
    "    print(all_epoch_acc, file=f_acc)\n",
    "    \n",
    "### evaluating the model with test set\n",
    "print(\"----------------------------- Test --------------------------------\")\n",
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "    running_loss = 0\n",
    "    running_corrects = 0\n",
    "\n",
    "    for data in test_loader:\n",
    "        inputs, labels = data \n",
    "\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad() # clear all gradients\n",
    "\n",
    "        outputs = model(inputs) # batch_size x num_classes\n",
    "        _, preds = torch.max(outputs.data, 1) # values, indices\n",
    "        loss = loss_fn(outputs, labels)\n",
    "\n",
    "        running_loss += loss.data.item() * inputs.size(0)\n",
    "        running_corrects += torch.sum(preds == labels.data).item()\n",
    "\n",
    "    # Visualize the loss and accuracy values.\n",
    "    print({\n",
    "    'time': np.round(time.time()-start_time, 5),\n",
    "    'test_loss': np.round(running_loss/ dataset_sizes['test'], 5),\n",
    "    'test_acc': np.round(running_corrects/ dataset_sizes['test'], 5),\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16013373",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b1b3da1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d58654c0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
