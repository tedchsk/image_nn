{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GPUs\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import numpy as np\n",
    "import time\n",
    "from typing import Type, Any, Callable, Union, List, Optional\n",
    "from torch import Tensor \n",
    "from torchsummary import summary\n",
    "if torch.cuda.is_available():\n",
    "    print(\"Using GPUs\")\n",
    "    device = torch.device(\"cuda\") \n",
    "else:\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "{'train': 50000, 'test': 5000, 'validation': 5000}\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(43)\n",
    "batch_size = 128\n",
    "\n",
    "### for CIFAR 10\n",
    "# stats = ((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n",
    "## for CIFAR 100\n",
    "stats = ((0.507, 0.487, 0.441), (0.267, 0.256, 0.276))\n",
    "\n",
    "transform = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.ToTensor(),\n",
    "    torchvision.transforms.Normalize(*stats),\n",
    "    torchvision.transforms.RandomCrop(32, padding=4, padding_mode='constant'),\n",
    "    torchvision.transforms.RandomHorizontalFlip(p=0.5)\n",
    "])\n",
    "\n",
    "train_set = torchvision.datasets.CIFAR100(root=\"data\", train=True, download=True, transform=transform)\n",
    "train_size = len(train_set)\n",
    "test_set = torchvision.datasets.CIFAR100(root=\"data\", train=False, download=True, transform=transform)\n",
    "test_set, validation_set = torch.utils.data.random_split(test_set, [5000, 5000])\n",
    "test_size = len(test_set)\n",
    "validation_size = len(validation_set)\n",
    "\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_set, batch_size, shuffle=True, num_workers=4, pin_memory=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_set, batch_size, num_workers=4, pin_memory=True)\n",
    "validation_loader = torch.utils.data.DataLoader(validation_set, batch_size, num_workers=4, pin_memory=True)\n",
    "\n",
    "data_loaders = {\"train\": train_loader, \"test\": test_loader, \"validation\": validation_loader}\n",
    "dataset_sizes = {\"train\": train_size, \"test\": test_size, \"validation\": validation_size}\n",
    "print(dataset_sizes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "### from https://pytorch.org/hub/pytorch_vision_resnet/\n",
    "\n",
    "class BasicBlock(nn.Module):\n",
    "\n",
    "    def __init__(self, inplanes, planes, stride=1, down=False):\n",
    "        super().__init__()\n",
    "            \n",
    "        self.conv1 = nn.Conv2d(inplanes, planes, stride=stride, kernel_size=3, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "        \n",
    "        self.downsample = None\n",
    "        \n",
    "        if down:\n",
    "            self.downsample = nn.Conv2d(inplanes, planes, kernel_size=1, stride=stride)\n",
    "        \n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        identity = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        \n",
    "        if self.downsample is not None:\n",
    "            identity = self.downsample(x)\n",
    "        \n",
    "        out += identity\n",
    "        out = self.relu(out)\n",
    "        \n",
    "        return out\n",
    "\n",
    "    \n",
    "\n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self, model_n, num_classes: int = 10):\n",
    "        super().__init__()\n",
    "\n",
    "        self.residual_layers = nn.ModuleList([])\n",
    "        self.model_n = model_n\n",
    "\n",
    "        ### begining layers\n",
    "        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, stride=1, padding='same')\n",
    "        self.bn1 = nn.BatchNorm2d(16)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        \n",
    "        \n",
    "        ######## ResNet blocks [16, 32, 64]\n",
    "        ### first block, 16 channels\n",
    "        for i in range(self.model_n):\n",
    "            self.residual_layers.append(BasicBlock(16, 16).to(device))\n",
    "            \n",
    "        \n",
    "        ### second block, 32 channels\n",
    "        for i in range(self.model_n):\n",
    "            if i == 0:\n",
    "                self.residual_layers.append(BasicBlock(16, 32, stride=2, down=True).to(device))\n",
    "            else:\n",
    "                self.residual_layers.append(BasicBlock(32, 32).to(device))\n",
    "                \n",
    "                \n",
    "        ### third block, 64 channels\n",
    "        for i in range(self.model_n):\n",
    "            if i == 0:\n",
    "                self.residual_layers.append(BasicBlock(32, 64, stride=2, down=True).to(device))\n",
    "                self.inplanes = 64\n",
    "            else:\n",
    "                self.residual_layers.append(BasicBlock(64, 64).to(device))\n",
    "        \n",
    "    \n",
    "        ### output layers\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.fc = nn.Linear(64, num_classes)\n",
    "\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "\n",
    "        ### begining layers\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        \n",
    "        ##### ResNet blocks\n",
    "        for i, layer in enumerate(self.residual_layers):\n",
    "            x = layer (x)\n",
    "            \n",
    "            \n",
    "        ### output layers\n",
    "        x = self.avgpool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc(x)\n",
    "\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 16, 32, 32]             448\n",
      "       BatchNorm2d-2           [-1, 16, 32, 32]              32\n",
      "              ReLU-3           [-1, 16, 32, 32]               0\n",
      "            Conv2d-4           [-1, 16, 32, 32]           2,320\n",
      "       BatchNorm2d-5           [-1, 16, 32, 32]              32\n",
      "              ReLU-6           [-1, 16, 32, 32]               0\n",
      "            Conv2d-7           [-1, 16, 32, 32]           2,320\n",
      "       BatchNorm2d-8           [-1, 16, 32, 32]              32\n",
      "              ReLU-9           [-1, 16, 32, 32]               0\n",
      "       BasicBlock-10           [-1, 16, 32, 32]               0\n",
      "           Conv2d-11           [-1, 16, 32, 32]           2,320\n",
      "      BatchNorm2d-12           [-1, 16, 32, 32]              32\n",
      "             ReLU-13           [-1, 16, 32, 32]               0\n",
      "           Conv2d-14           [-1, 16, 32, 32]           2,320\n",
      "      BatchNorm2d-15           [-1, 16, 32, 32]              32\n",
      "             ReLU-16           [-1, 16, 32, 32]               0\n",
      "       BasicBlock-17           [-1, 16, 32, 32]               0\n",
      "           Conv2d-18           [-1, 16, 32, 32]           2,320\n",
      "      BatchNorm2d-19           [-1, 16, 32, 32]              32\n",
      "             ReLU-20           [-1, 16, 32, 32]               0\n",
      "           Conv2d-21           [-1, 16, 32, 32]           2,320\n",
      "      BatchNorm2d-22           [-1, 16, 32, 32]              32\n",
      "             ReLU-23           [-1, 16, 32, 32]               0\n",
      "       BasicBlock-24           [-1, 16, 32, 32]               0\n",
      "           Conv2d-25           [-1, 32, 16, 16]           4,640\n",
      "      BatchNorm2d-26           [-1, 32, 16, 16]              64\n",
      "             ReLU-27           [-1, 32, 16, 16]               0\n",
      "           Conv2d-28           [-1, 32, 16, 16]           9,248\n",
      "      BatchNorm2d-29           [-1, 32, 16, 16]              64\n",
      "           Conv2d-30           [-1, 32, 16, 16]             544\n",
      "             ReLU-31           [-1, 32, 16, 16]               0\n",
      "       BasicBlock-32           [-1, 32, 16, 16]               0\n",
      "           Conv2d-33           [-1, 32, 16, 16]           9,248\n",
      "      BatchNorm2d-34           [-1, 32, 16, 16]              64\n",
      "             ReLU-35           [-1, 32, 16, 16]               0\n",
      "           Conv2d-36           [-1, 32, 16, 16]           9,248\n",
      "      BatchNorm2d-37           [-1, 32, 16, 16]              64\n",
      "             ReLU-38           [-1, 32, 16, 16]               0\n",
      "       BasicBlock-39           [-1, 32, 16, 16]               0\n",
      "           Conv2d-40           [-1, 32, 16, 16]           9,248\n",
      "      BatchNorm2d-41           [-1, 32, 16, 16]              64\n",
      "             ReLU-42           [-1, 32, 16, 16]               0\n",
      "           Conv2d-43           [-1, 32, 16, 16]           9,248\n",
      "      BatchNorm2d-44           [-1, 32, 16, 16]              64\n",
      "             ReLU-45           [-1, 32, 16, 16]               0\n",
      "       BasicBlock-46           [-1, 32, 16, 16]               0\n",
      "           Conv2d-47             [-1, 64, 8, 8]          18,496\n",
      "      BatchNorm2d-48             [-1, 64, 8, 8]             128\n",
      "             ReLU-49             [-1, 64, 8, 8]               0\n",
      "           Conv2d-50             [-1, 64, 8, 8]          36,928\n",
      "      BatchNorm2d-51             [-1, 64, 8, 8]             128\n",
      "           Conv2d-52             [-1, 64, 8, 8]           2,112\n",
      "             ReLU-53             [-1, 64, 8, 8]               0\n",
      "       BasicBlock-54             [-1, 64, 8, 8]               0\n",
      "           Conv2d-55             [-1, 64, 8, 8]          36,928\n",
      "      BatchNorm2d-56             [-1, 64, 8, 8]             128\n",
      "             ReLU-57             [-1, 64, 8, 8]               0\n",
      "           Conv2d-58             [-1, 64, 8, 8]          36,928\n",
      "      BatchNorm2d-59             [-1, 64, 8, 8]             128\n",
      "             ReLU-60             [-1, 64, 8, 8]               0\n",
      "       BasicBlock-61             [-1, 64, 8, 8]               0\n",
      "           Conv2d-62             [-1, 64, 8, 8]          36,928\n",
      "      BatchNorm2d-63             [-1, 64, 8, 8]             128\n",
      "             ReLU-64             [-1, 64, 8, 8]               0\n",
      "           Conv2d-65             [-1, 64, 8, 8]          36,928\n",
      "      BatchNorm2d-66             [-1, 64, 8, 8]             128\n",
      "             ReLU-67             [-1, 64, 8, 8]               0\n",
      "       BasicBlock-68             [-1, 64, 8, 8]               0\n",
      "AdaptiveAvgPool2d-69             [-1, 64, 1, 1]               0\n",
      "           Linear-70                  [-1, 100]           6,500\n",
      "================================================================\n",
      "Total params: 278,916\n",
      "Trainable params: 278,916\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.01\n",
      "Forward/backward pass size (MB): 5.06\n",
      "Params size (MB): 1.06\n",
      "Estimated Total Size (MB): 6.14\n",
      "----------------------------------------------------------------\n",
      "True torch.Size([16, 16, 3, 3])\n",
      "True torch.Size([16])\n",
      "True torch.Size([16])\n",
      "True torch.Size([16])\n",
      "True torch.Size([16, 16, 3, 3])\n",
      "True torch.Size([16])\n",
      "True torch.Size([16])\n",
      "True torch.Size([16])\n",
      "True torch.Size([16, 16, 3, 3])\n",
      "True torch.Size([16])\n",
      "True torch.Size([16])\n",
      "True torch.Size([16])\n",
      "True torch.Size([16, 16, 3, 3])\n",
      "True torch.Size([16])\n",
      "True torch.Size([16])\n",
      "True torch.Size([16])\n",
      "True torch.Size([16, 16, 3, 3])\n",
      "True torch.Size([16])\n",
      "True torch.Size([16])\n",
      "True torch.Size([16])\n",
      "True torch.Size([16, 16, 3, 3])\n",
      "True torch.Size([16])\n",
      "True torch.Size([16])\n",
      "True torch.Size([16])\n",
      "True torch.Size([32, 16, 3, 3])\n",
      "True torch.Size([32])\n",
      "True torch.Size([32])\n",
      "True torch.Size([32])\n",
      "True torch.Size([32, 32, 3, 3])\n",
      "True torch.Size([32])\n",
      "True torch.Size([32])\n",
      "True torch.Size([32])\n",
      "True torch.Size([32, 16, 1, 1])\n",
      "True torch.Size([32])\n",
      "True torch.Size([32, 32, 3, 3])\n",
      "True torch.Size([32])\n",
      "True torch.Size([32])\n",
      "True torch.Size([32])\n",
      "True torch.Size([32, 32, 3, 3])\n",
      "True torch.Size([32])\n",
      "True torch.Size([32])\n",
      "True torch.Size([32])\n",
      "True torch.Size([32, 32, 3, 3])\n",
      "True torch.Size([32])\n",
      "True torch.Size([32])\n",
      "True torch.Size([32])\n",
      "True torch.Size([32, 32, 3, 3])\n",
      "True torch.Size([32])\n",
      "True torch.Size([32])\n",
      "True torch.Size([32])\n",
      "True torch.Size([64, 32, 3, 3])\n",
      "True torch.Size([64])\n",
      "True torch.Size([64])\n",
      "True torch.Size([64])\n",
      "True torch.Size([64, 64, 3, 3])\n",
      "True torch.Size([64])\n",
      "True torch.Size([64])\n",
      "True torch.Size([64])\n",
      "True torch.Size([64, 32, 1, 1])\n",
      "True torch.Size([64])\n",
      "True torch.Size([64, 64, 3, 3])\n",
      "True torch.Size([64])\n",
      "True torch.Size([64])\n",
      "True torch.Size([64])\n",
      "True torch.Size([64, 64, 3, 3])\n",
      "True torch.Size([64])\n",
      "True torch.Size([64])\n",
      "True torch.Size([64])\n",
      "True torch.Size([64, 64, 3, 3])\n",
      "True torch.Size([64])\n",
      "True torch.Size([64])\n",
      "True torch.Size([64])\n",
      "True torch.Size([64, 64, 3, 3])\n",
      "True torch.Size([64])\n",
      "True torch.Size([64])\n",
      "True torch.Size([64])\n",
      "True torch.Size([16, 3, 3, 3])\n",
      "True torch.Size([16])\n",
      "True torch.Size([16])\n",
      "True torch.Size([16])\n",
      "True torch.Size([100, 64])\n",
      "True torch.Size([100])\n"
     ]
    }
   ],
   "source": [
    "#### Train Configurations, based on DSNet and ResNet paper\n",
    "model_n = 3\n",
    "epochs = 100\n",
    "milestones = [int(epochs*0.5), int(epochs*0.75)]\n",
    "momentum = 0.9\n",
    "weight_decay = 0.0005\n",
    "gamma = 0.1\n",
    "lr = 0.1\n",
    "\n",
    "model = ResNet(model_n, num_classes=100)\n",
    "model.to(device)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=lr, momentum=momentum)\n",
    "scheduler = optim.lr_scheduler.MultiStepLR(optimizer, milestones=milestones, gamma=gamma)\n",
    "\n",
    "summary(model, (3, 32, 32))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuration:  model:ResNet(small)  model_n: 3  batch size: 128  optimizer:SGD  lr: 0.1  epochs: 100\n",
      "----------------------------- Train --------------------------------\n",
      "Epoch 1/100\n",
      "------------------------------\n",
      "{'time': 10.54983, 'train_loss': 4.06348, 'train_acc': 0.0686, 'val_loss': 3.83767, 'val_acc': 0.0992}\n",
      "Epoch 2/100\n",
      "------------------------------\n",
      "{'time': 8.51099, 'train_loss': 3.53918, 'train_acc': 0.14928, 'val_loss': 3.57399, 'val_acc': 0.1622}\n",
      "Epoch 3/100\n",
      "------------------------------\n",
      "{'time': 8.29049, 'train_loss': 3.1133, 'train_acc': 0.2219, 'val_loss': 3.05406, 'val_acc': 0.2442}\n",
      "Epoch 4/100\n",
      "------------------------------\n",
      "{'time': 8.52674, 'train_loss': 2.78957, 'train_acc': 0.28572, 'val_loss': 2.75431, 'val_acc': 0.2986}\n",
      "Epoch 5/100\n",
      "------------------------------\n",
      "{'time': 8.45359, 'train_loss': 2.53348, 'train_acc': 0.33596, 'val_loss': 2.51307, 'val_acc': 0.3344}\n",
      "Epoch 6/100\n",
      "------------------------------\n",
      "{'time': 8.64396, 'train_loss': 2.3373, 'train_acc': 0.38004, 'val_loss': 2.45986, 'val_acc': 0.3582}\n",
      "Epoch 7/100\n",
      "------------------------------\n",
      "{'time': 8.52046, 'train_loss': 2.17814, 'train_acc': 0.41342, 'val_loss': 2.29726, 'val_acc': 0.3978}\n",
      "Epoch 8/100\n",
      "------------------------------\n",
      "{'time': 8.22205, 'train_loss': 2.04677, 'train_acc': 0.44308, 'val_loss': 2.22314, 'val_acc': 0.4188}\n",
      "Epoch 9/100\n",
      "------------------------------\n",
      "{'time': 8.51296, 'train_loss': 1.94429, 'train_acc': 0.4677, 'val_loss': 2.12281, 'val_acc': 0.4344}\n",
      "Epoch 10/100\n",
      "------------------------------\n",
      "{'time': 8.45822, 'train_loss': 1.85154, 'train_acc': 0.48806, 'val_loss': 1.99098, 'val_acc': 0.4692}\n",
      "Epoch 11/100\n",
      "------------------------------\n",
      "{'time': 8.38146, 'train_loss': 1.7816, 'train_acc': 0.50744, 'val_loss': 1.95015, 'val_acc': 0.4676}\n",
      "Epoch 12/100\n",
      "------------------------------\n",
      "{'time': 8.0426, 'train_loss': 1.70758, 'train_acc': 0.52698, 'val_loss': 2.05617, 'val_acc': 0.4548}\n",
      "Epoch 13/100\n",
      "------------------------------\n",
      "{'time': 8.35821, 'train_loss': 1.66008, 'train_acc': 0.53504, 'val_loss': 1.88331, 'val_acc': 0.4878}\n",
      "Epoch 14/100\n",
      "------------------------------\n",
      "{'time': 8.05229, 'train_loss': 1.60774, 'train_acc': 0.5495, 'val_loss': 1.81563, 'val_acc': 0.5134}\n",
      "Epoch 15/100\n",
      "------------------------------\n",
      "{'time': 8.45301, 'train_loss': 1.56826, 'train_acc': 0.55748, 'val_loss': 1.76825, 'val_acc': 0.5176}\n",
      "Epoch 16/100\n",
      "------------------------------\n",
      "{'time': 8.83569, 'train_loss': 1.52699, 'train_acc': 0.56842, 'val_loss': 1.68145, 'val_acc': 0.5354}\n",
      "Epoch 17/100\n",
      "------------------------------\n",
      "{'time': 8.80674, 'train_loss': 1.49289, 'train_acc': 0.57674, 'val_loss': 1.89336, 'val_acc': 0.4942}\n",
      "Epoch 18/100\n",
      "------------------------------\n",
      "{'time': 9.28646, 'train_loss': 1.4566, 'train_acc': 0.58646, 'val_loss': 1.72308, 'val_acc': 0.5308}\n",
      "Epoch 19/100\n",
      "------------------------------\n",
      "{'time': 8.64142, 'train_loss': 1.42864, 'train_acc': 0.59028, 'val_loss': 1.68442, 'val_acc': 0.5426}\n",
      "Epoch 20/100\n",
      "------------------------------\n",
      "{'time': 8.65355, 'train_loss': 1.39541, 'train_acc': 0.59846, 'val_loss': 1.67551, 'val_acc': 0.5472}\n",
      "Epoch 21/100\n",
      "------------------------------\n",
      "{'time': 8.30893, 'train_loss': 1.36804, 'train_acc': 0.6081, 'val_loss': 1.71308, 'val_acc': 0.5366}\n",
      "Epoch 22/100\n",
      "------------------------------\n",
      "{'time': 8.45951, 'train_loss': 1.33946, 'train_acc': 0.61558, 'val_loss': 1.67896, 'val_acc': 0.551}\n",
      "Epoch 23/100\n",
      "------------------------------\n",
      "{'time': 8.93187, 'train_loss': 1.32335, 'train_acc': 0.61942, 'val_loss': 1.65818, 'val_acc': 0.5462}\n",
      "Epoch 24/100\n",
      "------------------------------\n",
      "{'time': 9.15191, 'train_loss': 1.30062, 'train_acc': 0.62576, 'val_loss': 1.81273, 'val_acc': 0.531}\n",
      "Epoch 25/100\n",
      "------------------------------\n",
      "{'time': 8.55055, 'train_loss': 1.26634, 'train_acc': 0.63262, 'val_loss': 1.63697, 'val_acc': 0.5586}\n",
      "Epoch 26/100\n",
      "------------------------------\n",
      "{'time': 7.86408, 'train_loss': 1.25493, 'train_acc': 0.63444, 'val_loss': 1.66109, 'val_acc': 0.5464}\n",
      "Epoch 27/100\n",
      "------------------------------\n",
      "{'time': 9.00095, 'train_loss': 1.23734, 'train_acc': 0.63996, 'val_loss': 1.61256, 'val_acc': 0.5604}\n",
      "Epoch 28/100\n",
      "------------------------------\n",
      "{'time': 8.96769, 'train_loss': 1.21761, 'train_acc': 0.64452, 'val_loss': 1.61368, 'val_acc': 0.5652}\n",
      "Epoch 29/100\n",
      "------------------------------\n",
      "{'time': 8.65342, 'train_loss': 1.19762, 'train_acc': 0.6507, 'val_loss': 1.67972, 'val_acc': 0.5468}\n",
      "Epoch 30/100\n",
      "------------------------------\n",
      "{'time': 8.80107, 'train_loss': 1.18905, 'train_acc': 0.65242, 'val_loss': 1.59448, 'val_acc': 0.564}\n",
      "Epoch 31/100\n",
      "------------------------------\n",
      "{'time': 8.88554, 'train_loss': 1.16775, 'train_acc': 0.65758, 'val_loss': 1.6421, 'val_acc': 0.5568}\n",
      "Epoch 32/100\n",
      "------------------------------\n",
      "{'time': 8.61384, 'train_loss': 1.15651, 'train_acc': 0.66022, 'val_loss': 1.67115, 'val_acc': 0.563}\n",
      "Epoch 33/100\n",
      "------------------------------\n",
      "{'time': 9.14548, 'train_loss': 1.13911, 'train_acc': 0.66492, 'val_loss': 1.56138, 'val_acc': 0.5762}\n",
      "Epoch 34/100\n",
      "------------------------------\n",
      "{'time': 8.4325, 'train_loss': 1.12253, 'train_acc': 0.66842, 'val_loss': 1.59024, 'val_acc': 0.5818}\n",
      "Epoch 35/100\n",
      "------------------------------\n",
      "{'time': 9.05832, 'train_loss': 1.11359, 'train_acc': 0.67294, 'val_loss': 1.58956, 'val_acc': 0.567}\n",
      "Epoch 36/100\n",
      "------------------------------\n",
      "{'time': 8.3239, 'train_loss': 1.09964, 'train_acc': 0.6745, 'val_loss': 1.67389, 'val_acc': 0.5598}\n",
      "Epoch 37/100\n",
      "------------------------------\n",
      "{'time': 12.17757, 'train_loss': 1.09068, 'train_acc': 0.67798, 'val_loss': 1.50989, 'val_acc': 0.588}\n",
      "Epoch 38/100\n",
      "------------------------------\n",
      "{'time': 8.23957, 'train_loss': 1.07862, 'train_acc': 0.67832, 'val_loss': 1.56975, 'val_acc': 0.5782}\n",
      "Epoch 39/100\n",
      "------------------------------\n",
      "{'time': 8.11444, 'train_loss': 1.07272, 'train_acc': 0.68084, 'val_loss': 1.54895, 'val_acc': 0.5872}\n",
      "Epoch 40/100\n",
      "------------------------------\n",
      "{'time': 8.47098, 'train_loss': 1.05919, 'train_acc': 0.6863, 'val_loss': 1.56284, 'val_acc': 0.5874}\n",
      "Epoch 41/100\n",
      "------------------------------\n",
      "{'time': 8.88258, 'train_loss': 1.04597, 'train_acc': 0.68748, 'val_loss': 1.63304, 'val_acc': 0.5672}\n",
      "Epoch 42/100\n",
      "------------------------------\n",
      "{'time': 8.42285, 'train_loss': 1.03026, 'train_acc': 0.69152, 'val_loss': 1.66329, 'val_acc': 0.566}\n",
      "Epoch 43/100\n",
      "------------------------------\n",
      "{'time': 8.81547, 'train_loss': 1.0208, 'train_acc': 0.6943, 'val_loss': 1.57016, 'val_acc': 0.5804}\n",
      "Epoch 44/100\n",
      "------------------------------\n",
      "{'time': 8.50652, 'train_loss': 1.00959, 'train_acc': 0.69708, 'val_loss': 1.53577, 'val_acc': 0.5958}\n",
      "Epoch 45/100\n",
      "------------------------------\n",
      "{'time': 8.38021, 'train_loss': 1.00254, 'train_acc': 0.70002, 'val_loss': 1.57307, 'val_acc': 0.5822}\n",
      "Epoch 46/100\n",
      "------------------------------\n",
      "{'time': 8.84906, 'train_loss': 0.99163, 'train_acc': 0.70186, 'val_loss': 1.56558, 'val_acc': 0.5846}\n",
      "Epoch 47/100\n",
      "------------------------------\n",
      "{'time': 7.93629, 'train_loss': 0.97627, 'train_acc': 0.7067, 'val_loss': 1.54669, 'val_acc': 0.5832}\n",
      "Epoch 48/100\n",
      "------------------------------\n",
      "{'time': 8.21044, 'train_loss': 0.97151, 'train_acc': 0.7076, 'val_loss': 1.57094, 'val_acc': 0.5858}\n",
      "Epoch 49/100\n",
      "------------------------------\n",
      "{'time': 8.21302, 'train_loss': 0.96278, 'train_acc': 0.71212, 'val_loss': 1.5258, 'val_acc': 0.594}\n",
      "Epoch 50/100\n",
      "------------------------------\n",
      "{'time': 8.17157, 'train_loss': 0.95218, 'train_acc': 0.71454, 'val_loss': 1.59472, 'val_acc': 0.5858}\n",
      "Epoch 51/100\n",
      "------------------------------\n",
      "{'time': 7.76121, 'train_loss': 0.94804, 'train_acc': 0.71368, 'val_loss': 1.63547, 'val_acc': 0.581}\n",
      "Epoch 52/100\n",
      "------------------------------\n",
      "{'time': 8.05068, 'train_loss': 0.93479, 'train_acc': 0.71692, 'val_loss': 1.72576, 'val_acc': 0.5748}\n",
      "Epoch 53/100\n",
      "------------------------------\n",
      "{'time': 8.01281, 'train_loss': 0.92871, 'train_acc': 0.72102, 'val_loss': 1.5289, 'val_acc': 0.5916}\n",
      "Epoch 54/100\n",
      "------------------------------\n",
      "{'time': 8.57984, 'train_loss': 0.90894, 'train_acc': 0.72472, 'val_loss': 1.58438, 'val_acc': 0.5856}\n",
      "Epoch 55/100\n",
      "------------------------------\n",
      "{'time': 8.64537, 'train_loss': 0.91389, 'train_acc': 0.72174, 'val_loss': 1.55719, 'val_acc': 0.597}\n",
      "Epoch 56/100\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'time': 7.80876, 'train_loss': 0.91364, 'train_acc': 0.7226, 'val_loss': 1.61954, 'val_acc': 0.5756}\n",
      "Epoch 57/100\n",
      "------------------------------\n",
      "{'time': 7.88094, 'train_loss': 0.89883, 'train_acc': 0.72752, 'val_loss': 1.63311, 'val_acc': 0.5918}\n",
      "Epoch 58/100\n",
      "------------------------------\n",
      "{'time': 8.80987, 'train_loss': 0.89606, 'train_acc': 0.72724, 'val_loss': 1.57855, 'val_acc': 0.5944}\n",
      "Epoch 59/100\n",
      "------------------------------\n",
      "{'time': 8.1734, 'train_loss': 0.88586, 'train_acc': 0.72914, 'val_loss': 1.51004, 'val_acc': 0.608}\n",
      "Epoch 60/100\n",
      "------------------------------\n",
      "{'time': 7.99855, 'train_loss': 0.87878, 'train_acc': 0.73248, 'val_loss': 1.55224, 'val_acc': 0.5984}\n",
      "Epoch 61/100\n",
      "------------------------------\n",
      "{'time': 7.92424, 'train_loss': 0.87025, 'train_acc': 0.73726, 'val_loss': 1.60786, 'val_acc': 0.5812}\n",
      "Epoch 62/100\n",
      "------------------------------\n",
      "{'time': 8.22886, 'train_loss': 0.86627, 'train_acc': 0.7363, 'val_loss': 1.719, 'val_acc': 0.5608}\n",
      "Epoch 63/100\n",
      "------------------------------\n",
      "{'time': 8.09747, 'train_loss': 0.86, 'train_acc': 0.73728, 'val_loss': 1.61843, 'val_acc': 0.5918}\n",
      "Epoch 64/100\n",
      "------------------------------\n",
      "{'time': 7.86852, 'train_loss': 0.84712, 'train_acc': 0.7407, 'val_loss': 1.66157, 'val_acc': 0.583}\n",
      "Epoch 65/100\n",
      "------------------------------\n",
      "{'time': 8.1218, 'train_loss': 0.85395, 'train_acc': 0.73834, 'val_loss': 1.55045, 'val_acc': 0.5994}\n",
      "Epoch 66/100\n",
      "------------------------------\n",
      "{'time': 8.74599, 'train_loss': 0.84346, 'train_acc': 0.74062, 'val_loss': 1.60205, 'val_acc': 0.595}\n",
      "Epoch 67/100\n",
      "------------------------------\n",
      "{'time': 8.40099, 'train_loss': 0.83691, 'train_acc': 0.74166, 'val_loss': 1.57301, 'val_acc': 0.5984}\n",
      "Epoch 68/100\n",
      "------------------------------\n",
      "{'time': 8.00787, 'train_loss': 0.82836, 'train_acc': 0.74548, 'val_loss': 1.60044, 'val_acc': 0.5966}\n",
      "Epoch 69/100\n",
      "------------------------------\n",
      "{'time': 8.18608, 'train_loss': 0.82729, 'train_acc': 0.74518, 'val_loss': 1.54913, 'val_acc': 0.602}\n",
      "Epoch 70/100\n",
      "------------------------------\n",
      "{'time': 8.51821, 'train_loss': 0.81492, 'train_acc': 0.74926, 'val_loss': 1.60156, 'val_acc': 0.5884}\n",
      "Epoch 71/100\n",
      "------------------------------\n",
      "{'time': 8.57191, 'train_loss': 0.80677, 'train_acc': 0.75316, 'val_loss': 1.68962, 'val_acc': 0.5884}\n",
      "Epoch 72/100\n",
      "------------------------------\n",
      "{'time': 8.43502, 'train_loss': 0.80931, 'train_acc': 0.75104, 'val_loss': 1.73616, 'val_acc': 0.5812}\n",
      "Epoch 73/100\n",
      "------------------------------\n",
      "{'time': 8.35194, 'train_loss': 0.80323, 'train_acc': 0.75172, 'val_loss': 1.57711, 'val_acc': 0.5994}\n",
      "Epoch 74/100\n",
      "------------------------------\n",
      "{'time': 16.25936, 'train_loss': 0.79387, 'train_acc': 0.75228, 'val_loss': 1.55943, 'val_acc': 0.6094}\n",
      "Epoch 75/100\n",
      "------------------------------\n",
      "{'time': 8.77127, 'train_loss': 0.79504, 'train_acc': 0.75562, 'val_loss': 1.68798, 'val_acc': 0.5858}\n",
      "Epoch 76/100\n",
      "------------------------------\n",
      "{'time': 8.47913, 'train_loss': 0.78791, 'train_acc': 0.75586, 'val_loss': 1.66566, 'val_acc': 0.5894}\n",
      "Epoch 77/100\n",
      "------------------------------\n",
      "{'time': 8.28159, 'train_loss': 0.78376, 'train_acc': 0.7568, 'val_loss': 1.61686, 'val_acc': 0.6104}\n",
      "Epoch 78/100\n",
      "------------------------------\n",
      "{'time': 8.09835, 'train_loss': 0.77711, 'train_acc': 0.7589, 'val_loss': 1.66454, 'val_acc': 0.5912}\n",
      "Epoch 79/100\n",
      "------------------------------\n",
      "{'time': 7.99324, 'train_loss': 0.76909, 'train_acc': 0.76162, 'val_loss': 1.66912, 'val_acc': 0.5962}\n",
      "Epoch 80/100\n",
      "------------------------------\n",
      "{'time': 7.97863, 'train_loss': 0.78122, 'train_acc': 0.75674, 'val_loss': 1.6224, 'val_acc': 0.5896}\n",
      "Epoch 81/100\n",
      "------------------------------\n",
      "{'time': 8.16663, 'train_loss': 0.76242, 'train_acc': 0.76228, 'val_loss': 1.6745, 'val_acc': 0.5894}\n",
      "Epoch 82/100\n",
      "------------------------------\n",
      "{'time': 9.86244, 'train_loss': 0.75949, 'train_acc': 0.76286, 'val_loss': 1.58027, 'val_acc': 0.6006}\n",
      "Epoch 83/100\n",
      "------------------------------\n",
      "{'time': 10.11785, 'train_loss': 0.74842, 'train_acc': 0.76826, 'val_loss': 1.59075, 'val_acc': 0.6024}\n",
      "Epoch 84/100\n",
      "------------------------------\n",
      "{'time': 8.59469, 'train_loss': 0.7491, 'train_acc': 0.76624, 'val_loss': 1.68707, 'val_acc': 0.5946}\n",
      "Epoch 85/100\n",
      "------------------------------\n",
      "{'time': 8.48125, 'train_loss': 0.74873, 'train_acc': 0.7673, 'val_loss': 1.6329, 'val_acc': 0.5998}\n",
      "Epoch 86/100\n",
      "------------------------------\n",
      "{'time': 8.29025, 'train_loss': 0.73979, 'train_acc': 0.76876, 'val_loss': 1.59296, 'val_acc': 0.6032}\n",
      "Epoch 87/100\n",
      "------------------------------\n",
      "{'time': 8.41089, 'train_loss': 0.73822, 'train_acc': 0.7685, 'val_loss': 1.5974, 'val_acc': 0.6004}\n",
      "Epoch 88/100\n",
      "------------------------------\n",
      "{'time': 8.35352, 'train_loss': 0.72604, 'train_acc': 0.77294, 'val_loss': 1.67179, 'val_acc': 0.5962}\n",
      "Epoch 89/100\n",
      "------------------------------\n",
      "{'time': 8.207, 'train_loss': 0.72635, 'train_acc': 0.77144, 'val_loss': 1.64511, 'val_acc': 0.6042}\n",
      "Epoch 90/100\n",
      "------------------------------\n",
      "{'time': 8.1869, 'train_loss': 0.7223, 'train_acc': 0.77492, 'val_loss': 1.70436, 'val_acc': 0.5926}\n",
      "Epoch 91/100\n",
      "------------------------------\n",
      "{'time': 8.06459, 'train_loss': 0.5657, 'train_acc': 0.824, 'val_loss': 1.46633, 'val_acc': 0.6384}\n",
      "Epoch 92/100\n",
      "------------------------------\n",
      "{'time': 7.68946, 'train_loss': 0.51906, 'train_acc': 0.8389, 'val_loss': 1.44864, 'val_acc': 0.6374}\n",
      "Epoch 93/100\n",
      "------------------------------\n",
      "{'time': 8.22783, 'train_loss': 0.50663, 'train_acc': 0.84066, 'val_loss': 1.49353, 'val_acc': 0.6328}\n",
      "Epoch 94/100\n",
      "------------------------------\n",
      "{'time': 8.51527, 'train_loss': 0.4947, 'train_acc': 0.84692, 'val_loss': 1.46553, 'val_acc': 0.6402}\n",
      "Epoch 95/100\n",
      "------------------------------\n",
      "{'time': 8.52795, 'train_loss': 0.48485, 'train_acc': 0.84908, 'val_loss': 1.478, 'val_acc': 0.6316}\n",
      "Epoch 96/100\n",
      "------------------------------\n",
      "{'time': 8.32666, 'train_loss': 0.47897, 'train_acc': 0.8497, 'val_loss': 1.50288, 'val_acc': 0.6364}\n",
      "Epoch 97/100\n",
      "------------------------------\n",
      "{'time': 8.83053, 'train_loss': 0.47634, 'train_acc': 0.84968, 'val_loss': 1.47949, 'val_acc': 0.6388}\n",
      "Epoch 98/100\n",
      "------------------------------\n",
      "{'time': 8.61463, 'train_loss': 0.46977, 'train_acc': 0.85304, 'val_loss': 1.50251, 'val_acc': 0.6422}\n",
      "Epoch 99/100\n",
      "------------------------------\n",
      "{'time': 8.61601, 'train_loss': 0.46901, 'train_acc': 0.8519, 'val_loss': 1.51803, 'val_acc': 0.6358}\n",
      "Epoch 100/100\n",
      "------------------------------\n",
      "{'time': 8.26663, 'train_loss': 0.46214, 'train_acc': 0.85542, 'val_loss': 1.51255, 'val_acc': 0.6374}\n",
      "----------------------------- Test --------------------------------\n",
      "{'time': 8.81777, 'test_loss': 1.58258, 'test_acc': 0.626}\n"
     ]
    }
   ],
   "source": [
    "### Train loop + validation/ also test at the end\n",
    "print(\"Configuration: \", \"model:ResNet(small)\", \" model_n:\", model_n, \" batch size:\", batch_size, \n",
    "      \" optimizer:SGD\", \" lr:\", lr, \" epochs:\", epochs)\n",
    "\n",
    "print(\"----------------------------- Train --------------------------------\")\n",
    "for epoch in range(epochs):\n",
    "    start_time = time.time()\n",
    "    print(\"Epoch {}/{}\".format(epoch+1, epochs))\n",
    "    print(\"-\" * 30)\n",
    "    \n",
    "    \n",
    "    epoch_loss = {\"train\": 0.0, \"validation\": 0.0}\n",
    "    epoch_acc = {\"train\": 0.0, \"validation\": 0.0}\n",
    "    \n",
    "    running_loss = {\"train\": 0.0, \"validation\": 0.0}\n",
    "    running_corrects = {\"train\": 0, \"validation\": 0}\n",
    "    \n",
    "    for phase in [\"train\", \"validation\"]:\n",
    "        if phase == \"train\":\n",
    "            model.train(True)\n",
    "        else:\n",
    "            model.train(False)\n",
    "        \n",
    "        for data in data_loaders[phase]:\n",
    "            inputs, labels = data \n",
    "            \n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            optimizer.zero_grad() # clear all gradients\n",
    "            \n",
    "            outputs = model(inputs) # batch_size x num_classes\n",
    "            _, preds = torch.max(outputs.data, 1) # values, indices\n",
    "            loss = loss_fn(outputs, labels)\n",
    "            \n",
    "            if phase == \"train\":\n",
    "                loss.backward()  # compute gradients\n",
    "                optimizer.step() # update weights/biases\n",
    "               \n",
    "            running_loss[phase] += loss.data.item() * inputs.size(0)\n",
    "            running_corrects[phase] += torch.sum(preds == labels.data).item()\n",
    "        \n",
    "        epoch_loss[phase] = running_loss[phase] / dataset_sizes[phase]\n",
    "        epoch_acc[phase] =  running_corrects[phase] / dataset_sizes[phase]\n",
    "\n",
    "    # Visualize the loss and accuracy values.\n",
    "    print({\n",
    "        'time': np.round(time.time()-start_time, 5),\n",
    "        'train_loss': np.round(epoch_loss[\"train\"], 5),\n",
    "        'train_acc': np.round(epoch_acc[\"train\"], 5),\n",
    "        'val_loss': np.round(epoch_loss[\"validation\"], 5),\n",
    "        'val_acc': np.round(epoch_acc[\"validation\"], 5),\n",
    "    })\n",
    "    \n",
    "    scheduler.step()\n",
    "\n",
    "    \n",
    "    \n",
    "### evaluating the model with test set\n",
    "print(\"----------------------------- Test --------------------------------\")\n",
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "    running_loss = 0\n",
    "    running_corrects = 0\n",
    "\n",
    "    for data in test_loader:\n",
    "        inputs, labels = data \n",
    "\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad() # clear all gradients\n",
    "\n",
    "        outputs = model(inputs) # batch_size x num_classes\n",
    "        _, preds = torch.max(outputs.data, 1) # values, indices\n",
    "        loss = loss_fn(outputs, labels)\n",
    "\n",
    "        running_loss += loss.data.item() * inputs.size(0)\n",
    "        running_corrects += torch.sum(preds == labels.data).item()\n",
    "\n",
    "    # Visualize the loss and accuracy values.\n",
    "    print({\n",
    "    'time': np.round(time.time()-start_time, 5),\n",
    "    'test_loss': np.round(running_loss/ dataset_sizes['test'], 5),\n",
    "    'test_acc': np.round(running_corrects/ dataset_sizes['test'], 5),\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
